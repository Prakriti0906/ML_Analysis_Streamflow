{"cells":[{"cell_type":"markdown","metadata":{"id":"N5BWBoV8sPyB"},"source":["# **Start Section:**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tu3iL02U0vfa","outputId":"3309a578-d54e-4157-c0ec-8487953f736c","executionInfo":{"status":"ok","timestamp":1755072863919,"user_tz":-330,"elapsed":46823,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vauvSSPZ0ZKL","outputId":"05468339-2c03-4734-ad74-67c5d4c39fb1","executionInfo":{"status":"ok","timestamp":1755073150075,"user_tz":-330,"elapsed":286159,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: scikit-learn 1.6.1\n","Uninstalling scikit-learn-1.6.1:\n","  Successfully uninstalled scikit-learn-1.6.1\n","Collecting scikit-learn==1.5.2\n","  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n","Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed scikit-learn-1.5.2\n","Collecting bayesian-optimization\n","  Downloading bayesian_optimization-3.1.0-py3-none-any.whl.metadata (11 kB)\n","Collecting colorama>=0.4.6 (from bayesian-optimization)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (2.0.2)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (1.5.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->bayesian-optimization) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->bayesian-optimization) (3.6.0)\n","Downloading bayesian_optimization-3.1.0-py3-none-any.whl (36 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Installing collected packages: colorama, bayesian-optimization\n","Successfully installed bayesian-optimization-3.1.0 colorama-0.4.6\n","Collecting optuna\n","  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.42)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n","Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n","Collecting gpboost\n","  Downloading gpboost-1.6.1-py3-none-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from gpboost) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gpboost) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gpboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gpboost) (1.16.1)\n","Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.11/dist-packages (from gpboost) (1.5.2)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from gpboost) (4.4.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->gpboost) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->gpboost) (3.6.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (6.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (2.0.42)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (6.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2025.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->gpboost) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->gpboost) (4.14.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->gpboost) (1.17.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->gpboost) (3.2.3)\n","Downloading gpboost-1.6.1-py3-none-manylinux1_x86_64.whl (5.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gpboost\n","Successfully installed gpboost-1.6.1\n","Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.16.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.5.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n","Collecting ngboost\n","  Downloading ngboost-0.5.6-py3-none-any.whl.metadata (4.0 kB)\n","Collecting lifelines>=0.25 (from ngboost)\n","  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from ngboost) (2.0.2)\n","Collecting scikit-learn<2.0,>=1.6 (from ngboost)\n","  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: scipy>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from ngboost) (1.16.1)\n","Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.11/dist-packages (from ngboost) (4.67.1)\n","Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (2.2.2)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (3.10.0)\n","Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (1.8.0)\n","Collecting autograd-gamma>=0.3 (from lifelines>=0.25->ngboost)\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting formulaic>=0.2.2 (from lifelines>=0.25->ngboost)\n","  Downloading formulaic-1.2.0-py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.6->ngboost) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.6->ngboost) (3.6.0)\n","Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines>=0.25->ngboost)\n","  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (2.0.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.14.1)\n","Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.17.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.17.0)\n","Downloading ngboost-0.5.6-py3-none-any.whl (35 kB)\n","Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading formulaic-1.2.0-py3-none-any.whl (117 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: autograd-gamma\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=bcec2ef28402b300f520936355ebb645c0e24fc2c6b49c3dde876e6b309a22f9\n","  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n","Successfully built autograd-gamma\n","Installing collected packages: interface-meta, scikit-learn, autograd-gamma, formulaic, lifelines, ngboost\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.5.2\n","    Uninstalling scikit-learn-1.5.2:\n","      Successfully uninstalled scikit-learn-1.5.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed autograd-gamma-0.5.0 formulaic-1.2.0 interface-meta-1.3.0 lifelines-0.30.0 ngboost-0.5.6 scikit-learn-1.7.1\n","Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.11/dist-packages (2025.5.0)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (8.2.1)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (3.1.1)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (2025.3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (25.0)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (6.0.2)\n","Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (0.12.1)\n","Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (8.7.0)\n","Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (2.2.2)\n","Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (18.1.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask[dataframe]) (3.23.0)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2025.2)\n","Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.17.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n","  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.16.1)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.16.1)\n","Collecting lime\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.16.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.7.1)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (25.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n","Building wheels for collected packages: lime\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=63ea946ed99fdd5cf32ddb09f98a892a3942c5457f37f235e71de2bbdeff44fa\n","  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n","Successfully built lime\n","Installing collected packages: lime\n","Successfully installed lime-0.2.0.1\n","Collecting interpret\n","  Downloading interpret-0.7.2-py3-none-any.whl.metadata (1.2 kB)\n","Collecting interpret-core==0.7.2 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading interpret_core-0.7.2-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2.0.2)\n","Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2.2.2)\n","Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.7.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.5.1)\n","Requirement already satisfied: psutil>=5.6.2 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (5.9.5)\n","Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (6.17.1)\n","Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (7.34.0)\n","Requirement already satisfied: plotly>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (5.24.1)\n","Collecting SALib>=1.3.3 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading salib-1.5.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: shap>=0.28.5 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.48.0)\n","Requirement already satisfied: dill>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.3.8)\n","Collecting aplr>=10.6.1 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading aplr-10.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n","Collecting dash<3.0.0,>=2.0.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n","Collecting dash-cytoscape>=0.1.1 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading dash_cytoscape-1.0.2.tar.gz (4.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gevent>=1.3.6 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading gevent-25.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2.32.3)\n","Collecting Flask<3.1,>=1.0.4 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n","Collecting Werkzeug<3.1 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n","Collecting dash-html-components==2.0.0 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting dash-core-components==2.0.0 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting dash-table==5.0.0 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (8.7.0)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (4.14.1)\n","Collecting retrying (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (75.2.0)\n","Requirement already satisfied: greenlet>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.2.3)\n","Collecting zope.event (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading zope_event-5.1.1-py3-none-any.whl.metadata (5.0 kB)\n","Collecting zope.interface (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.8.15)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.1.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (25.0)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (26.2.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (6.4.2)\n","Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (5.7.1)\n","Collecting jedi>=0.16 (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (4.9.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2025.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=3.8.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (8.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2025.8.3)\n","Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.10.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.70.16)\n","Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.16.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18.1->interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (4.67.1)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.0.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.1.1)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.1.6)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (8.2.1)\n","Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.8.4)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (5.8.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.2.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.43.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19.2->interpret-core==0.7.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.0.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (3.23.0)\n","Collecting setuptools (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret)\n","  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret) (4.3.8)\n","Downloading interpret-0.7.2-py3-none-any.whl (1.4 kB)\n","Downloading interpret_core-0.7.2-py3-none-any.whl (16.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aplr-10.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n","Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n","Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n","Downloading gevent-25.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading salib-1.5.1-py3-none-any.whl (778 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.9/778.9 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flask-3.0.3-py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading retrying-1.4.2-py3-none-any.whl (10 kB)\n","Downloading zope_event-5.1.1-py3-none-any.whl (7.0 kB)\n","Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: dash-cytoscape\n","  Building wheel for dash-cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dash-cytoscape: filename=dash_cytoscape-1.0.2-py3-none-any.whl size=4010717 sha256=1ac301cd8fc7ab25943503d3d2a8146b42e2e5e97d4651a115452178d2ce8ff4\n","  Stored in directory: /root/.cache/pip/wheels/99/b1/ab/6c999ab288b4849d372e23c0a8f6ece7edb7ffeb8c97959ab0\n","Successfully built dash-cytoscape\n","Installing collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, setuptools, retrying, jedi, aplr, zope.interface, zope.event, Flask, SALib, interpret-core, gevent, dash, dash-cytoscape, interpret\n","  Attempting uninstall: Werkzeug\n","    Found existing installation: Werkzeug 3.1.3\n","    Uninstalling Werkzeug-3.1.3:\n","      Successfully uninstalled Werkzeug-3.1.3\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.2.0\n","    Uninstalling setuptools-75.2.0:\n","      Successfully uninstalled setuptools-75.2.0\n","  Attempting uninstall: Flask\n","    Found existing installation: Flask 3.1.1\n","    Uninstalling Flask-3.1.1:\n","      Successfully uninstalled Flask-3.1.1\n","Successfully installed Flask-3.0.3 SALib-1.5.1 Werkzeug-3.0.6 aplr-10.9.0 dash-2.18.2 dash-core-components-2.0.0 dash-cytoscape-1.0.2 dash-html-components-2.0.0 dash-table-5.0.0 gevent-25.5.1 interpret-0.7.2 interpret-core-0.7.2 jedi-0.19.2 retrying-1.4.2 setuptools-80.9.0 zope.event-5.1.1 zope.interface-7.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack"]},"id":"3567c5322d594be0afc818c7a214ae6e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting optunahub\n","  Downloading optunahub-0.3.1-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optunahub) (4.4.0)\n","Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (from optunahub) (3.1.45)\n","Collecting PyGithub>=1.59 (from optunahub)\n","  Downloading pygithub-2.7.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting pynacl>=1.4.0 (from PyGithub>=1.59->optunahub)\n","  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n","Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (2.32.3)\n","Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub>=1.59->optunahub) (2.10.1)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (4.14.1)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (2.5.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython->optunahub) (4.0.12)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (2.0.42)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optunahub) (1.1.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython->optunahub) (5.0.2)\n","Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub>=1.59->optunahub) (43.0.3)\n","Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub>=1.59->optunahub) (1.17.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (2025.8.3)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optunahub) (3.2.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub>=1.59->optunahub) (2.22)\n","Downloading optunahub-0.3.1-py3-none-any.whl (12 kB)\n","Downloading pygithub-2.7.0-py3-none-any.whl (416 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.5/416.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pynacl, PyGithub, optunahub\n","Successfully installed PyGithub-2.7.0 optunahub-0.3.1 pynacl-1.5.0\n","Collecting cmaes\n","  Downloading cmaes-0.12.0-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cmaes) (2.0.2)\n","Downloading cmaes-0.12.0-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: cmaes\n","Successfully installed cmaes-0.12.0\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n","Collecting kaleido\n","  Downloading kaleido-1.0.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (25.0)\n","Collecting choreographer>=1.0.5 (from kaleido)\n","  Downloading choreographer-1.0.9-py3-none-any.whl.metadata (5.6 kB)\n","Collecting logistro>=1.0.8 (from kaleido)\n","  Downloading logistro-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.11/dist-packages (from kaleido) (3.11.1)\n","Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.11/dist-packages (from choreographer>=1.0.5->kaleido) (3.20.1)\n","Downloading kaleido-1.0.0-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading choreographer-1.0.9-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading logistro-1.1.0-py3-none-any.whl (7.9 kB)\n","Installing collected packages: logistro, choreographer, kaleido\n","Successfully installed choreographer-1.0.9 kaleido-1.0.0 logistro-1.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["site"]},"id":"7329400686e14d9d8486aaaeed4cf90c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n","Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (1.0.0)\n","Requirement already satisfied: choreographer>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from kaleido) (1.0.9)\n","Requirement already satisfied: logistro>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from kaleido) (1.1.0)\n","Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.11/dist-packages (from kaleido) (3.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kaleido) (25.0)\n","Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.11/dist-packages (from choreographer>=1.0.5->kaleido) (3.20.1)\n","Collecting properscoring\n","  Downloading properscoring-0.1-py2.py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from properscoring) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from properscoring) (1.16.1)\n","Downloading properscoring-0.1-py2.py3-none-any.whl (23 kB)\n","Installing collected packages: properscoring\n","Successfully installed properscoring-0.1\n","Collecting XlsxWriter\n","  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n","Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: XlsxWriter\n","Successfully installed XlsxWriter-3.2.5\n","Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n","Collecting pgbm\n","  Downloading pgbm-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n","Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pgbm) (1.7.1)\n","Collecting ninja>=1.10.2.2 (from pgbm)\n","  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n","Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.11/dist-packages (from pgbm) (0.60.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.56->pgbm) (0.43.0)\n","Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba>=0.56->pgbm) (2.0.2)\n","Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (3.6.0)\n","Downloading pgbm-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ninja, pgbm\n","Successfully installed ninja-1.13.0 pgbm-2.3.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting cp\n","  Downloading cp-2020.12.3.tar.gz (1.4 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: cp\n","  Building wheel for cp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cp: filename=cp-2020.12.3-py3-none-any.whl size=1421 sha256=186100815975655d5cfb1d9e17b2f642238093cf2a50f4d207a664cee6b54e53\n","  Stored in directory: /root/.cache/pip/wheels/58/67/10/9ba963c5b021c764015a1463b9bb89a408fc37bbcde7436aa7\n","Successfully built cp\n","Installing collected packages: cp\n","Successfully installed cp-2020.12.3\n","Collecting mapie\n","  Downloading mapie-1.0.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: scikit-learn>=1.4 in /usr/local/lib/python3.11/dist-packages (from mapie) (1.7.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mapie) (1.16.1)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from mapie) (2.0.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4->mapie) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4->mapie) (3.6.0)\n","Downloading mapie-1.0.1-py3-none-any.whl (173 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: mapie\n","Successfully installed mapie-1.0.1\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting skorch\n","  Downloading skorch-1.2.0-py3-none-any.whl.metadata (11 kB)\n","Collecting puncc\n","  Downloading puncc-0.8.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from skorch) (2.0.2)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.7.1)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.16.1)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch) (0.9.0)\n","Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (4.67.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from puncc) (1.5.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from puncc) (3.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from puncc) (2.2.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->puncc) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->puncc) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->puncc) (1.17.0)\n","Downloading skorch-1.2.0-py3-none-any.whl (263 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading puncc-0.8.0-py3-none-any.whl (70 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: skorch, puncc\n","Successfully installed puncc-0.8.0 skorch-1.2.0\n","Found existing installation: scikit-learn 1.7.1\n","Uninstalling scikit-learn-1.7.1:\n","  Successfully uninstalled scikit-learn-1.7.1\n","Collecting scikit-learn==1.6.1\n","  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (3.6.0)\n","Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn\n","Successfully installed scikit-learn-1.6.1\n","Collecting numpy==1.26.4\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"6b9cec746b864dc0b068349ef03dba93"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting catboost\n","  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n","Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.16.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n","Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: catboost\n","Successfully installed catboost-1.2.8\n","Collecting pytorch-tabnet2\n","  Downloading pytorch_tabnet2-4.5.1-py3-none-any.whl.metadata (5.5 kB)\n","Collecting activations-plus>=0.1.1 (from pytorch-tabnet2)\n","  Downloading activations_plus-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet2) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet2) (1.6.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet2) (2.6.0+cu124)\n","Collecting torcheval (from pytorch-tabnet2)\n","  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pytorch-tabnet2) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pytorch-tabnet2) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pytorch-tabnet2) (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-tabnet2) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch-tabnet2) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch-tabnet2) (3.0.2)\n","Downloading pytorch_tabnet2-4.5.1-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading activations_plus-0.1.1-py3-none-any.whl (15 kB)\n","Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torcheval, activations-plus, pytorch-tabnet2\n","Successfully installed activations-plus-0.1.1 pytorch-tabnet2-4.5.1 torcheval-0.0.7\n"]}],"source":["# Uninstall existing scikit-learn to avoid conflicts\n","!pip uninstall -y scikit-learn\n","# Install specific versions of libraries to avoid conflicts\n","!pip install scikit-learn==1.5.2\n","!pip install bayesian-optimization\n","!pip install optuna\n","!pip install gpboost\n","!pip install shap\n","!pip install ngboost\n","!pip install dask[dataframe]\n","!pip install torch seaborn\n","!pip install lightgbm\n","!pip install xgboost\n","!pip install lime\n","!pip install interpret\n","!pip install optunahub\n","!pip install cmaes\n","!pip install plotly kaleido\n","!pip install openpyxl\n","!pip install -U kaleido\n","!pip install properscoring\n","!pip install XlsxWriter\n","!pip install cython\n","!pip install pgbm\n","!pip install torch\n","!pip install cp\n","!pip install mapie\n","!pip install torch skorch puncc\n","# Reinstall scikit-learn to the version required by ngboost\n","!pip uninstall -y scikit-learn\n","!pip install scikit-learn==1.6.1\n","# Reinstall numpy first\n","!pip install numpy==1.26.4  # Use the version compatible with catboost\n","# Reinstall catboost\n","!pip install catboost\n","!pip install pytorch-tabnet2"]},{"cell_type":"code","source":["# Restart the runtime to apply changes\n","import os\n","os._exit(00)"],"metadata":{"id":"3RVi2IpaL81J"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"zQpUolvBsh4Y","executionInfo":{"status":"ok","timestamp":1755073310908,"user_tz":-330,"elapsed":56088,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"45f3ec94-78ba-42dd-c3c9-ddf9b7c69168"},"outputs":[{"output_type":"stream","name":"stderr","text":["No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n","Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n","Creating extension directory /root/.cache/torch_extensions/py311_cu124/split_decision...\n","Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/split_decision/build.ninja...\n","Building extension module split_decision...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","Loading extension module split_decision...\n","Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n","No modifications detected for re-loaded extension module split_decision, skipping build step...\n","Loading extension module split_decision...\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import ngboost\n","from scipy.stats import randint\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.svm import SVR\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from gpboost import GPBoostRegressor\n","from ngboost import NGBRegressor\n","import optuna\n","import optunahub\n","from sklearn.experimental import enable_halving_search_cv\n","from sklearn.model_selection import HalvingGridSearchCV\n","from interpret import show\n","from interpret.blackbox import LimeTabular, ShapKernel\n","from optuna.samplers import RandomSampler\n","import random\n","import time\n","from ngboost.distns import Normal\n","from ngboost.scores import LogScore\n","from scipy.stats import norm\n","from optuna.samplers import BaseSampler\n","from optuna.samplers import GridSampler\n","from optuna.samplers import TPESampler\n","from optuna.samplers import PartialFixedSampler\n","from optuna.samplers import CmaEsSampler\n","from optuna.samplers import QMCSampler\n","from optuna.samplers import NSGAIIISampler\n","from optuna.samplers import NSGAIISampler\n","from optuna.samplers import BruteForceSampler\n","from optuna.samplers import GPSampler\n","from interpret import set_visualize_provider\n","from interpret.provider import InlineProvider\n","from interpret.glassbox import ExplainableBoostingRegressor\n","from interpret import show\n","import plotly.express as px\n","from io import BytesIO\n","from openpyxl import Workbook, load_workbook\n","import os\n","import properscoring as ps\n","import io\n","from openpyxl.drawing.image import Image as openpyxlImage\n","import warnings\n","import xlsxwriter\n","from openpyxl.drawing.image import Image\n","from pgbm.sklearn import HistGradientBoostingRegressor\n","import torch\n","from pgbm.torch import PGBM\n","import plotly.graph_objects as go\n","warnings.filterwarnings('ignore')\n","import pickle\n","import json\n","# from mapie.subsample import Subsample\n","# from mapie.regression import MapieRegressor\n","from deel.puncc.metrics import regression_sharpness, regression_mean_coverage\n","from deel.puncc.api.prediction import BasePredictor, DualPredictor\n","from deel.puncc.regression import SplitCP, CVPlus, CQR\n","from deel.puncc.plotting import plot_prediction_intervals\n","from sklearn.model_selection import train_test_split\n","from typing_extensions import TypedDict\n","from typing import Union\n","# from mapie.metrics import regression_coverage_score\n","from sklearn.model_selection import KFold\n","from PIL import Image as PImage\n","from pytorch_tabnet import TabNetRegressor"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"cxa5cdZ1s8Ir","colab":{"base_uri":"https://localhost:8080/"},"outputId":"35172b97-033f-4838-f1df-c77630de28fb","executionInfo":{"status":"ok","timestamp":1755074752597,"user_tz":-330,"elapsed":24,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data loaded successfully.\n","Test data loaded successfully.\n"]}],"source":["train_data_path = \"./drive/MyDrive/SCOUR/Scour_uncertainity/train.csv\"\n","test_data_path = \"./drive/MyDrive/SCOUR/Scour_uncertainity/test.csv\"\n","train_data = pd.read_csv(train_data_path)\n","test_data = pd.read_csv(test_data_path)\n","print(\"Training data loaded successfully.\")\n","print(\"Test data loaded successfully.\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"C-5Z-sdptBNr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755074753893,"user_tz":-330,"elapsed":28,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}},"outputId":"ad188fb4-aa8d-4c54-c80b-f83a612b1d4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Shape of training data: (154, 8)\n","First 5 rows of training data:\n","     Ps   Pw   Skew     Velocity     Depth     D50     Gradation     Scour  \n","0  0.7  1.5        0          2.9       6.6   70.00           1.2       0.6\n","1  0.7  1.5        0          3.0       5.3   70.00           1.2       0.6\n","2  1.3  3.3        0          0.8       4.8    0.48           1.8       0.4\n","3  1.0  4.3        0          2.9       9.7    0.30           1.4       3.7\n","4  0.7  0.5       20          1.4       1.8    1.10           3.5       0.3\n","\n","Shape of test data: (78, 8)\n","First 5 rows of test data:\n","     Ps   Pw   Skew     Velocity     Depth     D50     Gradation     Scour  \n","0  1.3  0.3       16          1.0       0.3    0.94           3.0       0.4\n","1  1.0  0.8        0          0.2       1.5    0.25           8.0       0.2\n","2  1.0  0.6       10          1.6       6.6    0.90           4.2       1.1\n","3  1.3  1.2        0          0.8       3.1    0.38           2.3       1.6\n","4  1.0  0.8        0          1.1       1.7   60.00           2.4       0.2\n"]}],"source":["print(\"\\nShape of training data:\", train_data.shape)\n","print(\"First 5 rows of training data:\\n\", train_data.head(5))\n","print(\"\\nShape of test data:\", test_data.shape)\n","print(\"First 5 rows of test data:\\n\", test_data.head(5))"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"vZcobC9VtDLU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755074755690,"user_tz":-330,"elapsed":5,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}},"outputId":"6e0e4ebd-5840-403e-a607-66cdb8c20188"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Shape of X_train: (154, 7)\n","Shape of y_train: (154,)\n","Shape of X_test: (78, 7)\n","Shape of y_test: (78,)\n"]}],"source":["X_train = train_data.iloc[:, :-1]\n","y_train = train_data.iloc[:, -1]\n","X_test = test_data.iloc[:, :-1]\n","y_test = test_data.iloc[:, -1]\n","x_test= X_test\n","print(\"\\nShape of X_train:\", X_train.shape)\n","print(\"Shape of y_train:\", y_train.shape)\n","print(\"Shape of X_test:\", X_test.shape)\n","print(\"Shape of y_test:\", y_test.shape)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"J6CtTvyStGcM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755074757156,"user_tz":-330,"elapsed":24,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}},"outputId":"e9504dda-5043-4e03-fbe4-0d735cd106cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","First five rows of normalized X_train:\n","[[-1.30505288 -0.05072804 -0.49867969  1.41932674  0.51129506  1.91265145\n","  -0.75772712]\n"," [-1.30505288 -0.05072804 -0.49867969  1.53187891  0.18675076  1.91265145\n","  -0.75772712]\n"," [ 1.56606345  1.51169548 -0.49867969 -0.94426887  0.06192603 -0.69389788\n","  -0.5721613 ]\n"," [ 0.13050529  2.37970854 -0.49867969  1.41932674  1.28520839 -0.70064672\n","  -0.69587185]\n"," [-1.30505288 -0.9187411   0.57841248 -0.26895584 -0.68702234 -0.6706519\n","  -0.04639146]]\n","\n","First five rows of normalized X_test:\n","[[ 1.56606345 -1.09234371  0.36299405 -0.71916453 -1.06149653 -0.67665086\n","  -0.20102964]\n"," [ 0.13050529 -0.65833718 -0.49867969 -1.6195819  -0.76191718 -0.70252139\n","   1.34535224]\n"," [ 0.13050529 -0.83193979  0.0398664  -0.0438515   0.51129506 -0.6781506\n","   0.17010201]\n"," [ 1.56606345 -0.31113196 -0.49867969 -0.94426887 -0.36247805 -0.69764723\n","  -0.41752311]\n"," [ 0.13050529 -0.65833718 -0.49867969 -0.60661235 -0.71198729  1.53771627\n","  -0.38659547]]\n"]}],"source":["# Apply z-score normalization\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Print the first five rows of the normalized data\n","print(\"\\nFirst five rows of normalized X_train:\")\n","print(X_train[:5])\n","\n","print(\"\\nFirst five rows of normalized X_test:\")\n","print(X_test[:5])"]},{"cell_type":"markdown","metadata":{"id":"QVvIIfafc2bL"},"source":["# **Functions:**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ck8-bH33tI6s","executionInfo":{"status":"ok","timestamp":1755073539627,"user_tz":-330,"elapsed":24,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[],"source":["feature_names = ['Ps', 'Pw', 'skew', 'Velocity', 'Depth', 'D50', 'Gradation']"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"whJFQ_J60ZKP","executionInfo":{"status":"ok","timestamp":1755073539750,"user_tz":-330,"elapsed":82,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[],"source":["def get_best_model_params(results, model_name):\n","    # Map model names to dictionary keys, assuming keys are strings like 'XGBoost' and not objects\n","    model_keys = {\n","        'LightGBM': 'LightGBM',\n","        'XGBoost': 'XGBoost',\n","        'GPBoost': 'GPBoost',\n","        'GBM': 'Gradient Boosting',\n","        'CatBoost': 'CatBoost',\n","        'NGBoost': 'NGBoost',\n","        'HGBR' : 'HistGradientBoosting',\n","        'PGBM' : 'PGBM',\n","        'TabNet': 'TabNet'\n","    }\n","\n","    # Ensure the requested model name is valid\n","    if model_name not in model_keys:\n","        raise ValueError(f\"Model name '{model_name}' is not recognized. Available models are: {list(model_keys.keys())}\")\n","\n","    # Filter out entries for the specified model\n","    model_entries = {key: value for key, value in results.items() if key[0] == model_keys[model_name]}\n","\n","    # Find the entry with the best (lowest) 'best_score'\n","    best_entry_key, best_entry_value = min(model_entries.items(), key=lambda item: item[1]['best_score'])\n","\n","    # Return the best hyperparameters\n","    return best_entry_value['best_params']"]},{"cell_type":"code","source":["def quantile_regression_print(predictions_df, file_path):\n","    # Extract actual values\n","    actual_values = predictions_df['Actual'].values\n","\n","    # Debugging: Print the first few actual values\n","    print(\"First few actual values:\", actual_values[:5])\n","\n","    # Calculate coverage for the specific interval (0.05 to 0.95)\n","    lower_quantile = 0.05\n","    median_quantile = 0.5\n","    upper_quantile = 0.95\n","\n","    lower_preds = predictions_df[lower_quantile].values\n","    median_preds = predictions_df[median_quantile].values\n","    upper_preds = predictions_df[upper_quantile].values\n","\n","    in_interval = ((actual_values >= lower_preds) & (actual_values <= upper_preds))\n","    coverage = in_interval.mean()\n","    print(f\"Coverage of 90% prediction interval: {coverage * 100:.2f}%\")\n","\n","    # Create a new Excel workbook and add a worksheet\n","    wb = Workbook()\n","    ws = wb.active\n","    ws.title = \"quantile_regression_print\"\n","\n","    # Plot actual vs. all predicted quantiles\n","    num_points = len(predictions_df)\n","    indices = np.arange(num_points)\n","\n","    plt.figure(figsize=(12, 6))\n","    plt.plot(indices, actual_values[:num_points], label='Actual Scour', marker='o', linestyle='-', color='black')\n","\n","    # Loop over all columns assumed to be quantile predictions\n","    for column in predictions_df.columns:\n","        if column != 'Actual':  # Skip the actual values column\n","            plt.plot(indices, predictions_df[column][:num_points],\n","                     label=f'Predicted Quantile {column}', linestyle='--')\n","\n","    plt.xlabel('Sample Number')\n","    plt.ylabel('Scour')\n","    plt.title('Actual vs. Predicted Quantile Scour')\n","    plt.legend(loc='upper left', fontsize='small', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n","\n","    # Save the plot to a BytesIO object\n","    img_data = BytesIO()\n","    plt.savefig(img_data, format='png', bbox_inches='tight')\n","    plt.close()\n","    img_data.seek(0)\n","\n","    # Insert the image into the Excel sheet\n","    img = Image(img_data)\n","    ws.add_image(img, 'A1')\n","\n","    # Plot actual values and specific prediction intervals (0.05, 0.5, 0.95)\n","    plt.figure(figsize=(12, 6))\n","    plt.plot(indices, actual_values, label='Actual Scour', marker='o', linestyle='-', color='black')  # Connect points with a line\n","    plt.plot(indices, median_preds, label=f'Median Prediction ({median_quantile})', marker='x', linestyle='-', color='blue')\n","    plt.fill_between(\n","        indices,\n","        lower_preds,\n","        upper_preds,\n","        color='blue',\n","        alpha=0.5,\n","        label=f'Prediction Interval ({lower_quantile}-{upper_quantile})'\n","    )\n","    plt.xlabel('Sample Number')\n","    plt.ylabel(' Scour')\n","    plt.title('Actual Scour with Prediction Intervals')\n","    plt.legend(loc='upper left', fontsize='small', bbox_to_anchor=(1, 1))\n","\n","    # Save the second plot to another BytesIO object\n","    img_data = BytesIO()\n","    plt.savefig(img_data, format='png', bbox_inches='tight')\n","    plt.close()\n","    img_data.seek(0)\n","\n","    # Insert the second image into the Excel sheet\n","    img = Image(img_data)\n","    ws.add_image(img, 'A30')  # Adjust the cell position as needed\n","\n","    # Save the workbook\n","    wb.save(file_path)"],"metadata":{"id":"a0WGm_FHEn8C","executionInfo":{"status":"ok","timestamp":1755073539766,"user_tz":-330,"elapsed":9,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"zY1gSHGV0ZKQ","executionInfo":{"status":"ok","timestamp":1755073539771,"user_tz":-330,"elapsed":3,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[],"source":["def evaluation_features_print(predictions_df, X_test, file_path):\n","    # Ensure X_test is a DataFrame\n","    if isinstance(X_test, np.ndarray):\n","        X_test = pd.DataFrame(X_test, columns=feature_names)\n","    X_test.columns = feature_names\n","\n","    # Get quantile columns from predictions_df except 'Actual'\n","    quantile_columns = [col for col in predictions_df.columns if col != 'Actual']\n","\n","    # Check if the Excel file already exists\n","    if os.path.exists(file_path):\n","        wb = load_workbook(file_path)\n","        ws = wb.create_sheet(title=\"New Evaluation Features\")\n","    else:\n","        wb = Workbook()\n","        ws = wb.active\n","        ws.title = \"evaluation_features_print\"\n","\n","    image_row = 1  # Where to start images\n","\n","    for feature_to_plot in feature_names:\n","        feature_values = X_test[feature_to_plot]\n","        plot_df = predictions_df.copy()\n","        plot_df[feature_to_plot] = feature_values.values\n","\n","        # Sort by current feature to plot lines well\n","        plot_df = plot_df.sort_values(by=feature_to_plot)\n","\n","        # Begin Matplotlib plot\n","        plt.figure(figsize=(6, 4))\n","        # Plot each quantile as a line\n","        for quantile in quantile_columns:\n","            plt.plot(plot_df[feature_to_plot], plot_df[quantile], label=f\"{quantile}\")\n","\n","        # Plot actual values as scatter\n","        plt.scatter(plot_df[feature_to_plot], plot_df['Actual'], color='black', s=12, label=\"Actual Scour\")\n","\n","        plt.title(f\"Predicted Quantiles vs. {feature_to_plot}\")\n","        plt.xlabel(feature_to_plot)\n","        plt.ylabel(\"Scour\")\n","        plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n","        plt.tight_layout()\n","\n","        # Save figure to a BytesIO stream\n","        img_bytes = BytesIO()\n","        plt.savefig(img_bytes, format=\"png\")\n","        plt.close()\n","        img_bytes.seek(0)\n","\n","        img = Image(img_bytes)\n","        img.anchor = f\"A{image_row}\"\n","        ws.add_image(img)\n","\n","        image_row += 20  # Adjust as you like\n","\n","    wb.save(file_path)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"5wdzN4QM0ZKQ","executionInfo":{"status":"ok","timestamp":1755073539867,"user_tz":-330,"elapsed":97,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[],"source":["def evaluate_uncertainity_matrix(predictions_df, quantiles, excel_file_path, model_name='Model'):\n","\n","   # Extract the actual target values\n","    y_true = predictions_df['Actual']\n","\n","    # Open existing Excel file\n","    wb = load_workbook(filename=excel_file_path)\n","\n","    # Create unique sheet names\n","    def get_unique_sheet_name(wb, base_name):\n","        sheet_name = base_name\n","        i = 1\n","        while sheet_name in wb.sheetnames:\n","            sheet_name = f\"{base_name}_{i}\"\n","            i += 1\n","        return sheet_name\n","\n","    # Create separate sheets for plots and values\n","    plots_sheet_title = get_unique_sheet_name(wb, 'Plots')\n","    values_sheet_title = get_unique_sheet_name(wb, 'Values')\n","\n","    ws_plots = wb.create_sheet(title=plots_sheet_title)\n","    ws_values = wb.create_sheet(title=values_sheet_title)\n","\n","    # Positions to place images\n","    image_positions = ['A1', 'A25', 'A49', 'A73']  # Adjust as needed\n","\n","    ### 1. Validity / Coverage ###\n","\n","    # Compute empirical coverage for each quantile\n","    empirical_quantiles = []\n","    for q in quantiles:\n","        coverage = (predictions_df[q] >= y_true).mean()\n","        empirical_quantiles.append(coverage)\n","\n","    # Plot theoretical quantiles vs empirical quantiles\n","    plt.figure(figsize=(10, 6))\n","    sns.lineplot(x=quantiles, y=quantiles, color=\"magenta\", linestyle='--', linewidth=2, label=\"Ideal\")\n","    sns.lineplot(x=quantiles, y=empirical_quantiles, color=\"blue\", linewidth=2, label=\"Empirical\")\n","    sns.scatterplot(x=quantiles, y=empirical_quantiles, color=\"blue\", s=50)\n","    plt.xlabel(\"Nominal Quantile Levels\")\n","    plt.ylabel(\"Empirical Quantile Levels\")\n","    plt.title(f\"Validity / Coverage - {model_name}\")\n","    plt.legend()\n","\n","    # Save plot to buffer\n","    buffer = io.BytesIO()\n","    plt.savefig(buffer, format='png')\n","    plt.close()\n","    buffer.seek(0)\n","\n","    # Create an Image object\n","    img = openpyxlImage(buffer)\n","    img.width = 640\n","    img.height = 480\n","\n","    # Add the image to the plots worksheet\n","    ws_plots.add_image(img, image_positions[0])\n","\n","    ### 2. Sharpness / Interval Length ###\n","\n","    # Define coverage levels to evaluate\n","    coverage_levels = [0.6, 0.8, 0.9]\n","    average_interval_lengths = []\n","\n","    # Compute average interval lengths for each coverage level\n","    for c in coverage_levels:\n","        lower_q = (1 - c) / 2\n","        upper_q = 1 - lower_q\n","        # Find the nearest quantiles in our quantiles list\n","        lower_quantile = min(quantiles, key=lambda x: abs(x - lower_q))\n","        upper_quantile = min(quantiles, key=lambda x: abs(x - upper_q))\n","\n","        # Compute interval length for each observation\n","        interval_length = predictions_df[upper_quantile] - predictions_df[lower_quantile]\n","        avg_interval_length = interval_length.mean()\n","        average_interval_lengths.append(avg_interval_length)\n","        # Write interval length information to the values worksheet\n","        ws_values.append([f'Coverage level: {c*100:.0f}%', f'Interval: [{lower_quantile}, {upper_quantile}]', f'Average Interval Length: {avg_interval_length:.4f}'])\n","\n","    # Plot coverage levels vs average interval lengths\n","    plt.figure(figsize=(10, 6))\n","    plt.plot([c*100 for c in coverage_levels], average_interval_lengths, marker='o')\n","    plt.xlabel('Coverage Level (%)')\n","    plt.ylabel('Average Interval Length')\n","    plt.title(f'Sharpness / Interval Length - {model_name}')\n","\n","    # Save plot to buffer\n","    buffer = io.BytesIO()\n","    plt.savefig(buffer, format='png')\n","    plt.close()\n","    buffer.seek(0)\n","\n","    # Create an Image object\n","    img = openpyxlImage(buffer)\n","    img.width = 640\n","    img.height = 480\n","\n","    # Add image to the plots worksheet\n","    ws_plots.add_image(img, image_positions[1])\n","\n","    ### 3. Negative Log-Likelihood (NLL) ###\n","\n","    # Use the 5th and 95th percentiles to estimate standard deviation\n","    if 0.05 in quantiles and 0.95 in quantiles:\n","        z_lower = norm.ppf(0.05)  # z-score for 5% quantile (~ -1.6449)\n","        z_upper = norm.ppf(0.95)  # z-score for 95% quantile (~ +1.6449)\n","\n","        # Extract quantile predictions\n","        q_lower = predictions_df[0.05]\n","        q_upper = predictions_df[0.95]\n","\n","    elif 0.1 in quantiles and 0.9 in quantiles:\n","        z_lower = norm.ppf(0.1)  # z-score for 10% quantile (~ -1.2816)\n","        z_upper = norm.ppf(0.9)  # z-score for 90% quantile (~ +1.2816)\n","\n","        # Extract quantile predictions\n","        q_lower = predictions_df[0.1]\n","        q_upper = predictions_df[0.9]\n","    else:\n","        raise ValueError(\"Required quantiles for NLL estimation not found in quantiles list.\")\n","\n","    # Use median as the mean estimate\n","    if 0.5 in quantiles:\n","        q_median = predictions_df[0.5]\n","    else:\n","        # If 0.5 quantile is not available, use the middle quantile\n","        q_median = predictions_df[quantiles[len(quantiles)//2]]\n","\n","    # Estimate standard deviation for each observation\n","    std_estimates = (q_upper - q_lower) / (z_upper - z_lower)\n","\n","    # Ensure standard deviations are positive and non-zero\n","    std_estimates = std_estimates.clip(lower=1e-6)\n","\n","    # Extract mean estimates (median predictions)\n","    mean_estimates = q_median\n","\n","    # Compute Negative Log-Likelihood for each observation\n","    nll = -norm.logpdf(y_true, loc=mean_estimates, scale=std_estimates)\n","\n","    # Compute average NLL\n","    average_nll = nll.mean()\n","    # Write average NLL to the values worksheet\n","    ws_values.append(['Average Negative Log-Likelihood (NLL)', average_nll])\n","\n","    # Write NLL values to the values worksheet\n","    ws_values.append(['NLL Values'])\n","    for value in nll:\n","        ws_values.append([value])\n","\n","    # Plot ECDF of NLL values\n","    plt.figure(figsize=(10, 6))\n","    sns.ecdfplot(nll, color='blue', linewidth=2)\n","    plt.xlabel('Negative Log-Likelihood (NLL)')\n","    plt.ylabel('ECDF')\n","    plt.title(f'NLL ECDF - {model_name}')\n","\n","    # Save plot to buffer\n","    buffer = io.BytesIO()\n","    plt.savefig(buffer, format='png')\n","    plt.close()\n","    buffer.seek(0)\n","\n","    # Create an Image object\n","    img = openpyxlImage(buffer)\n","    img.width = 640\n","    img.height = 480\n","\n","    # Add image to the plots worksheet\n","    ws_plots.add_image(img, image_positions[2])\n","\n","    ### 4. Continuous Ranked Probability Score (CRPS) ###\n","\n","    # Prepare ensemble of quantile predictions for each observation\n","    ensemble_predictions = predictions_df[quantiles].to_numpy()\n","\n","    # Ensure quantile predictions are sorted for each observation\n","    ensemble_predictions.sort(axis=1)\n","\n","    # Compute CRPS for each observation using ensemble predictions\n","    crps_values = ps.crps_ensemble(y_true, ensemble_predictions)\n","\n","    # Compute average CRPS\n","    average_crps = crps_values.mean()\n","    # Write average CRPS to the values worksheet\n","    ws_values.append(['Average Continuous Ranked Probability Score (CRPS)', average_crps])\n","\n","    # Write CRPS values to the values worksheet\n","    ws_values.append(['CRPS Values'])\n","    for value in crps_values:\n","        ws_values.append([value])\n","\n","    # Plot ECDF of CRPS values\n","    plt.figure(figsize=(10, 6))\n","    sns.ecdfplot(crps_values, color='green', linewidth=2)\n","    plt.xlabel('Continuous Ranked Probability Score (CRPS)')\n","    plt.ylabel('ECDF')\n","    plt.title(f'CRPS ECDF - {model_name}')\n","\n","    # Save plot to buffer\n","    buffer = io.BytesIO()\n","    plt.savefig(buffer, format='png')\n","    plt.close()\n","    buffer.seek(0)\n","\n","    # Create an Image object\n","    img = openpyxlImage(buffer)\n","    img.width = 640\n","    img.height = 480\n","\n","    # Add image to the plots worksheet\n","    ws_plots.add_image(img, image_positions[3])\n","\n","    # Save the workbook\n","    wb.save(excel_file_path)\n","\n","    # Return a dictionary of results\n","    results = {\n","        'empirical_quantiles': empirical_quantiles,\n","        'average_interval_lengths': average_interval_lengths,\n","        'coverage_levels': coverage_levels,\n","        'average_nll': average_nll,\n","        'average_crps': average_crps,\n","        'nll_values': nll,\n","        'crps_values': crps_values\n","    }\n","\n","    return results"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"R2noCRwMdM4N","executionInfo":{"status":"ok","timestamp":1755073539934,"user_tz":-330,"elapsed":68,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[],"source":["def calibrate_and_plot_intervals(predictions_df, excel_file_path, alpha=0.1, max_samples=1000, random_seed=42):\n","    # Extract necessary columns\n","    lower = predictions_df[0.05].fillna(0)\n","    upper = predictions_df[0.95].fillna(0)\n","    pred = predictions_df[0.5].fillna(0)\n","    labels = predictions_df['Actual'].fillna(0)\n","\n","    # Problem setup\n","    total_samples = labels.shape[0]\n","    n = min(max_samples, total_samples)  # Ensure n does not exceed the number of samples\n","\n","    # Ensure there are enough samples for both calibration and validation\n","    if total_samples <= n:\n","        n = total_samples // 2\n","\n","    # Split the data into calibration and validation sets\n","    np.random.seed(random_seed)  # Set the random seed for reproducibility\n","    idx = np.array([1] * n + [0] * (total_samples - n)) > 0\n","    np.random.shuffle(idx)\n","    cal_labels, val_labels = labels[idx], labels[~idx]\n","    cal_upper, val_upper = upper[idx], upper[~idx]\n","    cal_lower, val_lower = lower[idx], lower[~idx]\n","    cal_pred, val_pred = pred[idx], pred[~idx]\n","\n","    # Calculate uncertainty intervals\n","    cal_U = cal_upper - cal_lower\n","    val_U = val_upper - val_lower\n","\n","    # Avoid division by zero by replacing zero intervals with a small number\n","    cal_U[cal_U == 0] = np.finfo(float).eps\n","    val_U[val_U == 0] = np.finfo(float).eps\n","\n","    # Get scores\n","    cal_scores = np.abs(cal_pred - cal_labels) / cal_U\n","\n","    # Debugging: Check for NaN in scores\n","    if np.isnan(cal_scores).any():\n","        print(\"NaN values found in cal_scores. Check data integrity.\")\n","\n","    # Get the score quantile\n","    qhat = np.quantile(cal_scores, np.ceil((n + 1) * (1 - alpha)) / n, interpolation='higher')\n","\n","    # Deploy (output=lower and upper adjusted quantiles)\n","    prediction_sets = [val_pred - val_U * qhat, val_pred + val_U * qhat]\n","\n","    # Calculate empirical coverage (before and after calibration)\n","    prediction_sets_uncalibrated = [val_lower, val_upper]\n","    empirical_coverage_uncalibrated = ((val_labels >= prediction_sets_uncalibrated[0]) & (val_labels <= prediction_sets_uncalibrated[1])).mean() * 100\n","    print(f\"The empirical coverage before calibration is: {empirical_coverage_uncalibrated:.2f}%\")\n","\n","    empirical_coverage = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean() * 100\n","    print(f\"The empirical coverage after calibration is: {empirical_coverage:.2f}%\")\n","\n","    # Create a DataFrame with all the necessary data\n","    data = pd.DataFrame({\n","        'Index': np.arange(len(val_labels)),\n","        'Uncalibrated Lower': val_lower,\n","        'Uncalibrated Upper': val_upper,\n","        'Calibrated Lower': prediction_sets[0],\n","        'Calibrated Upper': prediction_sets[1],\n","        'True Label': val_labels,\n","        'Predicted Value': val_pred\n","    })\n","\n","    plt.figure(figsize=(14, 8))\n","\n","    # Plot the uncalibrated prediction intervals as a shaded area\n","    plt.fill_between(\n","        data['Index'],\n","        data['Uncalibrated Lower'],\n","        data['Uncalibrated Upper'],\n","        color='blue',\n","        alpha=0.5,\n","        label='Uncalibrated Prediction Interval'\n","    )\n","\n","    # Plot the calibrated prediction intervals as a shaded area\n","    plt.fill_between(\n","        data['Index'],\n","        data['Calibrated Lower'],\n","        data['Calibrated Upper'],\n","        color='lightgreen',\n","        alpha=0.5,\n","        label='Calibrated Prediction Interval'\n","    )\n","\n","    # Plot the true labels as points and connect them with a line\n","    plt.plot(\n","        data['Index'],\n","        data['True Label'],\n","        'o-',\n","        color='red',\n","        markersize=4,\n","        label='Actual Value'\n","    )\n","\n","    # Plot the predicted values as points and connect them with a line\n","    plt.plot(\n","        data['Index'],\n","        data['Predicted Value'],\n","        'o-',\n","        color='black',\n","        markersize=4,\n","        label='Predicted Value'\n","    )\n","\n","    plt.xlabel('Sample Number')\n","    plt.ylabel('Scour')\n","    plt.title('Calibrated and Uncalibrated Prediction Intervals with True and Predicted Values')\n","    plt.legend(loc='upper left', fontsize='small', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n","    plt.tight_layout()\n","\n","    # Save the plot as an image\n","    image_path = 'plot.png'\n","    plt.savefig(image_path)\n","    plt.close()\n","\n","    # Load the existing Excel file\n","    workbook = load_workbook(excel_file_path)\n","\n","    # Create a new sheet for the plot\n","    new_sheet_name = \"calibrate_and_plot_intervals\"\n","    workbook.create_sheet(title=new_sheet_name)\n","\n","    # Insert the image into the new sheet\n","    sheet = workbook[new_sheet_name]\n","    img = Image(image_path)\n","    sheet.add_image(img, 'A1')\n","\n","    # Save the workbook\n","    workbook.save(excel_file_path)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"waUpsaSDdQkG","executionInfo":{"status":"ok","timestamp":1755073539967,"user_tz":-330,"elapsed":30,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[],"source":["def plot_quantile_intervals_to_excel(predictions_df, file_path, alpha=0.1):\n","    \"\"\"\n","    Plots conformal prediction intervals and their coverage, and saves the plots to an Excel file.\n","\n","    Parameters:\n","    - predictions_df: DataFrame containing prediction quantiles and actual values.\n","    - file_path: Path to the Excel file where plots will be saved.\n","    - alpha: Desired coverage level (default is 0.1).\n","    \"\"\"\n","    # Extract mean prediction and uncertainty\n","    mean_prediction = predictions_df[0.5]\n","    uncertainty = predictions_df[0.95] - predictions_df[0.05]\n","    actual_values = predictions_df['Actual']\n","\n","    # Calculate conformal scores\n","    conformal_scores = np.abs(mean_prediction - actual_values) / uncertainty\n","\n","    # Function to find weighted quantile\n","    def weighted_quantile(values, quantile, sample_weight=None):\n","        values = np.array(values)\n","        if sample_weight is None:\n","            sample_weight = np.ones(len(values))\n","        sorter = np.argsort(values)\n","        values, sample_weight = values[sorter], sample_weight[sorter]\n","        weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n","        weighted_quantiles /= np.sum(sample_weight)\n","        return np.interp(quantile, weighted_quantiles, values)\n","\n","    # Calculate weighted quantile\n","    weights = np.ones_like(conformal_scores)  # Uniform weights for simplicity\n","    quantile = weighted_quantile(conformal_scores, 1 - alpha, sample_weight=weights)\n","\n","    # Calculate prediction intervals\n","    lower_bound = mean_prediction - quantile * uncertainty\n","    upper_bound = mean_prediction + quantile * uncertainty\n","\n","    # Naive conformal prediction\n","    naive_quantile = np.quantile(conformal_scores, 1 - alpha)\n","    naive_lower_bound = mean_prediction - naive_quantile * uncertainty\n","    naive_upper_bound = mean_prediction + naive_quantile * uncertainty\n","\n","    # Coverage calculation (not plotted, just for potential diagnostics)\n","    weighted_coverage_points = (actual_values >= lower_bound) & (actual_values <= upper_bound)\n","    naive_coverage_points = (actual_values >= naive_lower_bound) & (actual_values <= naive_upper_bound)\n","\n","    # Visualization using Matplotlib\n","    fig, ax = plt.subplots(figsize=(10, 5))\n","\n","    x = np.arange(len(predictions_df))\n","    # Actual Values\n","    ax.plot(x, actual_values, label='Actual', color='black', linewidth=2)\n","\n","    # Mean Prediction\n","    ax.plot(x, mean_prediction, label='Mean Prediction', color='darkorange', linewidth=2)\n","\n","    # Weighted Prediction Interval (blue fill)\n","    ax.fill_between(x, lower_bound, upper_bound, color='blue', alpha=0.3, label='Weighted Interval')\n","    # Optionally, plot the bounds as lines if you want:\n","    # ax.plot(x, lower_bound, color='blue', linewidth=1, linestyle='--')\n","    # ax.plot(x, upper_bound, color='blue', linewidth=1, linestyle='--')\n","\n","    # Naive Prediction Interval (red fill)\n","    ax.fill_between(x, naive_lower_bound, naive_upper_bound, color='red', alpha=0.3, label='Naive Interval')\n","    # Optionally, plot the bounds as lines:\n","    # ax.plot(x, naive_lower_bound, color='red', linewidth=1, linestyle='--')\n","    # ax.plot(x, naive_upper_bound, color='red', linewidth=1, linestyle='--')\n","\n","    ax.set_title('Quantile Prediction Intervals')\n","    ax.set_xlabel('Sample Number')\n","    ax.set_ylabel('Scour')\n","    ax.grid(False)\n","    ax.set_facecolor('white')\n","\n","    # Place the legend outside the plot\n","    ax.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), borderaxespad=0.0)\n","\n","    plt.tight_layout(rect=[0,0,0.80,1.0])  # Make space for legend\n","\n","    # Save the plot to a BytesIO object\n","    img_data = BytesIO()\n","    plt.savefig(img_data, format='png', bbox_inches='tight')\n","    plt.close()\n","    img_data.seek(0)\n","\n","    # Add image to Excel\n","    if os.path.exists(file_path):\n","        wb = load_workbook(file_path)\n","        ws = wb.create_sheet(title=\"plot_quantile_intervals_to_excel\")\n","    else:\n","        wb = Workbook()\n","        ws = wb.active\n","        ws.title = \"plot_quantile_intervals_to_excel\"\n","\n","    img = Image(img_data)\n","    img.anchor = 'A1'\n","    ws.add_image(img)\n","    ws.column_dimensions['A'].width = 30\n","    wb.save(file_path)"]},{"cell_type":"markdown","metadata":{"id":"54GBQEKIMTH1"},"source":["# **Hyperparameter Tuning using Autosampler Optuna**"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Zh1Meg2-NC3F","executionInfo":{"status":"ok","timestamp":1755074479540,"user_tz":-330,"elapsed":251,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"outputs":[],"source":["best_scores_autosampler = {('Random Forest', 'MedianPruner'): {'best_score': 0.12510864483186684,\n","  'best_params': {'n_estimators': 500,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 10,\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'log2',\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.12510864483186684,\n","  'test_rmse': 0.35370700421657875,\n","  'test_corr_coef': 0.9473214040214425,\n","  'pruner': 'MedianPruner'},\n"," ('Random Forest', 'NopPruner'): {'best_score': 0.12046534236002056,\n","  'best_params': {'n_estimators': 700,\n","   'criterion': 'absolute_error',\n","   'max_depth': 10,\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'log2',\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.12046534236002056,\n","  'test_rmse': 0.34708117546190914,\n","  'test_corr_coef': 0.9498134261288462,\n","  'pruner': 'NopPruner'},\n"," ('Random Forest', 'PatientPruner'): {'best_score': 0.12408160544616127,\n","  'best_params': {'n_estimators': 500,\n","   'criterion': 'squared_error',\n","   'max_depth': 30,\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'log2',\n","   'max_leaf_nodes': 50,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.12408160544616127,\n","  'test_rmse': 0.35225219012258996,\n","  'test_corr_coef': 0.9477444667323718,\n","  'pruner': 'PatientPruner'},\n"," ('Random Forest', 'PercentilePruner'): {'best_score': 0.14192433802056953,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'squared_error',\n","   'max_depth': 10,\n","   'min_samples_split': 5,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.14192433802056953,\n","  'test_rmse': 0.37672846722881126,\n","  'test_corr_coef': 0.9396265659109715,\n","  'pruner': 'PercentilePruner'},\n"," ('Random Forest',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.1342439721270424, 'best_params': {'n_estimators': 500,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 10,\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': None,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001}, 'test_mse': 0.1342439721270424, 'test_rmse': 0.3663931933415827, 'test_corr_coef': 0.9415546128845363, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('Random Forest', 'HyperbandPruner'): {'best_score': 0.13288365989137368,\n","  'best_params': {'n_estimators': 200,\n","   'criterion': 'squared_error',\n","   'max_depth': 10,\n","   'min_samples_split': 5,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.13288365989137368,\n","  'test_rmse': 0.36453211091942733,\n","  'test_corr_coef': 0.941751867541519,\n","  'pruner': 'HyperbandPruner'},\n"," ('Random Forest', 'ThresholdPruner'): {'best_score': 0.1285992087711724,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 40,\n","   'min_samples_split': 5,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': None,\n","   'min_impurity_decrease': 0.1,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.1285992087711724,\n","  'test_rmse': 0.358607318345809,\n","  'test_corr_coef': 0.9428788297945659,\n","  'pruner': 'ThresholdPruner'},\n"," ('Random Forest', 'WilcoxonPruner'): {'best_score': 0.14236767968966665,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 30,\n","   'min_samples_split': 5,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.14236767968966665,\n","  'test_rmse': 0.37731641852650233,\n","  'test_corr_coef': 0.939699247004225,\n","  'pruner': 'WilcoxonPruner'},\n"," ('Gradient Boosting', 'MedianPruner'): {'best_score': 0.10845065799802021,\n","  'best_params': {'loss': 'absolute_error',\n","   'learning_rate': 0.1,\n","   'n_estimators': 700,\n","   'subsample': 1.0,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.1,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'log2',\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': None,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': None,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.10845065799802021,\n","  'test_rmse': 0.3293184750329386,\n","  'test_corr_coef': 0.9503242302132353,\n","  'pruner': 'MedianPruner'},\n"," ('Gradient Boosting', 'NopPruner'): {'best_score': 0.0889433834479747,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.2,\n","   'n_estimators': 500,\n","   'subsample': 0.9,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 7,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 0.5,\n","   'alpha': 0.1,\n","   'verbose': 0,\n","   'max_leaf_nodes': 10,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.0889433834479747,\n","  'test_rmse': 0.2982337731511552,\n","  'test_corr_coef': 0.9595962006230822,\n","  'pruner': 'NopPruner'},\n"," ('Gradient Boosting', 'PatientPruner'): {'best_score': 0.152087015040121,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.01,\n","   'n_estimators': 500,\n","   'subsample': 0.5,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 3,\n","   'min_impurity_decrease': 0.1,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'sqrt',\n","   'alpha': 0.9,\n","   'verbose': 0,\n","   'max_leaf_nodes': 50,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': None,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.152087015040121,\n","  'test_rmse': 0.3899833522602228,\n","  'test_corr_coef': 0.9310072121466791,\n","  'pruner': 'PatientPruner'},\n"," ('Gradient Boosting', 'PercentilePruner'): {'best_score': 0.1085338024107077,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.05,\n","   'n_estimators': 200,\n","   'subsample': 0.9,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 7,\n","   'min_impurity_decrease': 0.1,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 0.5,\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': 50,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 20,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.1085338024107077,\n","  'test_rmse': 0.32944468793821474,\n","  'test_corr_coef': 0.9573800974128435,\n","  'pruner': 'PercentilePruner'},\n"," ('Gradient Boosting',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.11275300441902505, 'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.2,\n","   'n_estimators': 300,\n","   'subsample': 0.9,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.01,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': None,\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': None,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 20,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.001}, 'test_mse': 0.11275300441902505, 'test_rmse': 0.3357871415331818, 'test_corr_coef': 0.9521358408056418, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('Gradient Boosting', 'HyperbandPruner'): {'best_score': 0.14931451252240666,\n","  'best_params': {'loss': 'absolute_error',\n","   'learning_rate': 0.05,\n","   'n_estimators': 200,\n","   'subsample': 1.0,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.1,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'log2',\n","   'alpha': 0.1,\n","   'verbose': 0,\n","   'max_leaf_nodes': 50,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': None,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.14931451252240666,\n","  'test_rmse': 0.3864123607267328,\n","  'test_corr_coef': 0.9345265880695094,\n","  'pruner': 'HyperbandPruner'},\n"," ('Gradient Boosting', 'ThresholdPruner'): {'best_score': 0.12120592757422323,\n","  'best_params': {'loss': 'absolute_error',\n","   'learning_rate': 0.1,\n","   'n_estimators': 300,\n","   'subsample': 0.9,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.01,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'sqrt',\n","   'alpha': 0.1,\n","   'verbose': 0,\n","   'max_leaf_nodes': None,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': None,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.01},\n","  'test_mse': 0.12120592757422323,\n","  'test_rmse': 0.3481464168625368,\n","  'test_corr_coef': 0.943829548984507,\n","  'pruner': 'ThresholdPruner'},\n"," ('Gradient Boosting', 'WilcoxonPruner'): {'best_score': 0.12267332802693258,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.2,\n","   'n_estimators': 300,\n","   'subsample': 1.0,\n","   'criterion': 'squared_error',\n","   'min_samples_split': 5,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 7,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'sqrt',\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': None,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.12267332802693258,\n","  'test_rmse': 0.3502475239411873,\n","  'test_corr_coef': 0.9433832222125687,\n","  'pruner': 'WilcoxonPruner'},\n"," ('XGBoost', 'MedianPruner'): {'best_score': 0.09029623329899747,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.7,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.09029623329899747,\n","  'test_rmse': 0.30049331656294365,\n","  'test_corr_coef': 0.9587837468414612,\n","  'pruner': 'MedianPruner'},\n"," ('XGBoost', 'NopPruner'): {'best_score': 0.08985870195827282,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.15,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.7,\n","   'colsample_bytree': 0.7,\n","   'colsample_bylevel': 0.7,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.08985870195827282,\n","  'test_rmse': 0.29976441075997134,\n","  'test_corr_coef': 0.9600171811862284,\n","  'pruner': 'NopPruner'},\n"," ('XGBoost', 'PatientPruner'): {'best_score': 0.09693013390372655,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.05,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.5,\n","   'colsample_bylevel': 0.7,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.09693013390372655,\n","  'test_rmse': 0.3113360465858821,\n","  'test_corr_coef': 0.9554805601571981,\n","  'pruner': 'PatientPruner'},\n"," ('XGBoost', 'PercentilePruner'): {'best_score': 0.10132620571388763,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'max_depth': 5,\n","   'min_child_weight': 1,\n","   'gamma': 0.1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.10132620571388763,\n","  'test_rmse': 0.31831777473758455,\n","  'test_corr_coef': 0.9533855069006654,\n","  'pruner': 'PercentilePruner'},\n"," ('XGBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.0958791546703723,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.01,\n","   'max_depth': 5,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.0958791546703723,\n","  'test_rmse': 0.30964359297484634,\n","  'test_corr_coef': 0.9563645870356832,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('XGBoost', 'HyperbandPruner'): {'best_score': 0.1082957786406958,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.1,\n","   'max_depth': 3,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.1082957786406958,\n","  'test_rmse': 0.32908323968366393,\n","  'test_corr_coef': 0.9519048947383398,\n","  'pruner': 'HyperbandPruner'},\n"," ('XGBoost', 'ThresholdPruner'): {'best_score': 0.09938239798275944,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.7,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.09938239798275944,\n","  'test_rmse': 0.31524973906850334,\n","  'test_corr_coef': 0.9548372936715677,\n","  'pruner': 'ThresholdPruner'},\n"," ('XGBoost', 'WilcoxonPruner'): {'best_score': 0.1114529726997407,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.05,\n","   'max_depth': 5,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.7,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.1114529726997407,\n","  'test_rmse': 0.3338457318878597,\n","  'test_corr_coef': 0.948956688134115,\n","  'pruner': 'WilcoxonPruner'},\n"," ('LightGBM', 'MedianPruner'): {'best_score': 0.09222151057908767,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'num_leaves': 15,\n","   'max_depth': 5,\n","   'min_child_samples': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.7,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 0,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09222151057908767,\n","  'test_rmse': 0.30367994760781897,\n","  'test_corr_coef': 0.9575447400290927,\n","  'pruner': 'MedianPruner'},\n"," ('LightGBM', 'NopPruner'): {'best_score': 0.09968321751963735,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'num_leaves': 31,\n","   'max_depth': 3,\n","   'min_child_samples': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 1.0,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 1,\n","   'min_child_weight': 1e-05,\n","   'bagging_freq': 0,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09968321751963735,\n","  'test_rmse': 0.3157264916341949,\n","  'test_corr_coef': 0.9542957424882237,\n","  'pruner': 'NopPruner'},\n"," ('LightGBM', 'PatientPruner'): {'best_score': 0.09714112400122255,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.15,\n","   'num_leaves': 63,\n","   'max_depth': 3,\n","   'min_child_samples': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 1,\n","   'min_child_weight': 0.1,\n","   'bagging_freq': 0,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09714112400122255,\n","  'test_rmse': 0.3116747086326103,\n","  'test_corr_coef': 0.955886744525236,\n","  'pruner': 'PatientPruner'},\n"," ('LightGBM', 'PercentilePruner'): {'best_score': 0.08558030029083012,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'num_leaves': 15,\n","   'max_depth': 5,\n","   'min_child_samples': 1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 5,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08558030029083012,\n","  'test_rmse': 0.29254110871949285,\n","  'test_corr_coef': 0.9615452545244726,\n","  'pruner': 'PercentilePruner'},\n"," ('LightGBM', 'SuccessiveHalvingPruner'): {'best_score': 0.09635999698825654,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'num_leaves': 63,\n","   'max_depth': 3,\n","   'min_child_samples': 1,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.7,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 1,\n","   'min_child_weight': 0.001,\n","   'bagging_freq': 0,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09635999698825654,\n","  'test_rmse': 0.31041906672795816,\n","  'test_corr_coef': 0.9557975931097965,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('LightGBM', 'HyperbandPruner'): {'best_score': 0.08293921959889271,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.1,\n","   'num_leaves': 63,\n","   'max_depth': -1,\n","   'min_child_samples': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.1,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08293921959889271,\n","  'test_rmse': 0.2879917005729379,\n","  'test_corr_coef': 0.9628250648708369,\n","  'pruner': 'HyperbandPruner'},\n"," ('LightGBM', 'ThresholdPruner'): {'best_score': 0.08676524760404458,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'num_leaves': 15,\n","   'max_depth': 7,\n","   'min_child_samples': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 5,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08676524760404458,\n","  'test_rmse': 0.2945594126896042,\n","  'test_corr_coef': 0.9609693020809187,\n","  'pruner': 'ThresholdPruner'},\n"," ('LightGBM', 'WilcoxonPruner'): {'best_score': 0.08752277011657707,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.05,\n","   'num_leaves': 15,\n","   'max_depth': 5,\n","   'min_child_samples': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08752277011657707,\n","  'test_rmse': 0.29584247517315204,\n","  'test_corr_coef': 0.9602149080708673,\n","  'pruner': 'WilcoxonPruner'},\n"," ('GPBoost', 'MedianPruner'): {'best_score': 0.10212938973683373,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'max_depth': 3,\n","   'num_leaves': 63,\n","   'min_child_samples': 1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.01,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.10212938973683373,\n","  'test_rmse': 0.3195768917441212,\n","  'test_corr_coef': 0.9531324137094551,\n","  'pruner': 'MedianPruner'},\n"," ('GPBoost', 'NopPruner'): {'best_score': 0.09978206398034087,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.05,\n","   'max_depth': 3,\n","   'num_leaves': 15,\n","   'min_child_samples': 1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.5,\n","   'min_child_weight': 0.1,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09978206398034087,\n","  'test_rmse': 0.31588299096396577,\n","  'test_corr_coef': 0.9541789788560355,\n","  'pruner': 'NopPruner'},\n"," ('GPBoost', 'PatientPruner'): {'best_score': 0.08922422210650882,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'max_depth': -1,\n","   'num_leaves': 15,\n","   'min_child_samples': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.1,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08922422210650882,\n","  'test_rmse': 0.29870423851446903,\n","  'test_corr_coef': 0.9593521000230474,\n","  'pruner': 'PatientPruner'},\n"," ('GPBoost', 'PercentilePruner'): {'best_score': 0.08922422210650882,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'max_depth': -1,\n","   'num_leaves': 15,\n","   'min_child_samples': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 1e-05,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08922422210650882,\n","  'test_rmse': 0.29870423851446903,\n","  'test_corr_coef': 0.9593521000230474,\n","  'pruner': 'PercentilePruner'},\n"," ('GPBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.10244349128455586,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'max_depth': 3,\n","   'num_leaves': 15,\n","   'min_child_samples': 1,\n","   'subsample': 1.0,\n","   'colsample_bytree': 1.0,\n","   'reg_alpha': 0.5,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.001,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.10244349128455586,\n","  'test_rmse': 0.32006794791818166,\n","  'test_corr_coef': 0.9529415685408233,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('GPBoost', 'HyperbandPruner'): {'best_score': 0.10380817468560068,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'max_depth': 5,\n","   'num_leaves': 31,\n","   'min_child_samples': 1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.5,\n","   'reg_lambda': 0,\n","   'min_child_weight': 1e-05,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.10380817468560068,\n","  'test_rmse': 0.3221927601384002,\n","  'test_corr_coef': 0.9528999902904025,\n","  'pruner': 'HyperbandPruner'},\n"," ('GPBoost', 'ThresholdPruner'): {'best_score': 0.0987853693895994,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.15,\n","   'max_depth': 3,\n","   'num_leaves': 15,\n","   'min_child_samples': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.1,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.0987853693895994,\n","  'test_rmse': 0.3143013989622054,\n","  'test_corr_coef': 0.9545465834260042,\n","  'pruner': 'ThresholdPruner'},\n"," ('GPBoost', 'WilcoxonPruner'): {'best_score': 0.09746228862099782,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'max_depth': 3,\n","   'num_leaves': 63,\n","   'min_child_samples': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0,\n","   'reg_lambda': 1.0,\n","   'min_child_weight': 0.1,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09746228862099782,\n","  'test_rmse': 0.3121895075446928,\n","  'test_corr_coef': 0.9560918488254501,\n","  'pruner': 'WilcoxonPruner'},\n"," ('CatBoost', 'MedianPruner'): {'best_score': 0.1027345763146008,\n","  'best_params': {'iterations': 1000,\n","   'learning_rate': 0.05,\n","   'depth': 8,\n","   'l2_leaf_reg': 7,\n","   'border_count': 32,\n","   'min_data_in_leaf': 5,\n","   'rsm': 0.6,\n","   'bagging_temperature': 1,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1027345763146008,\n","  'test_rmse': 0.32052234916554695,\n","  'test_corr_coef': 0.9528696676866157,\n","  'pruner': 'MedianPruner'},\n"," ('CatBoost', 'NopPruner'): {'best_score': 0.10608432900660457,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.1,\n","   'depth': 6,\n","   'l2_leaf_reg': 3,\n","   'border_count': 32,\n","   'min_data_in_leaf': 10,\n","   'rsm': 0.6,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10608432900660457,\n","  'test_rmse': 0.32570589341705897,\n","  'test_corr_coef': 0.9510437053953181,\n","  'pruner': 'NopPruner'},\n"," ('CatBoost', 'PatientPruner'): {'best_score': 0.10146578295486733,\n","  'best_params': {'iterations': 1000,\n","   'learning_rate': 0.05,\n","   'depth': 6,\n","   'l2_leaf_reg': 7,\n","   'border_count': 32,\n","   'min_data_in_leaf': 10,\n","   'rsm': 0.6,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10146578295486733,\n","  'test_rmse': 0.31853694127191484,\n","  'test_corr_coef': 0.9532680684984001,\n","  'pruner': 'PatientPruner'},\n"," ('CatBoost', 'PercentilePruner'): {'best_score': 0.10208631062341576,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.1,\n","   'depth': 10,\n","   'l2_leaf_reg': 5,\n","   'border_count': 32,\n","   'min_data_in_leaf': 5,\n","   'rsm': 0.6,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10208631062341576,\n","  'test_rmse': 0.3195094844029137,\n","  'test_corr_coef': 0.9536489292255467,\n","  'pruner': 'PercentilePruner'},\n"," ('CatBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.1003834647979198,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.1,\n","   'depth': 8,\n","   'l2_leaf_reg': 9,\n","   'border_count': 32,\n","   'min_data_in_leaf': 1,\n","   'rsm': 0.6,\n","   'bagging_temperature': 0,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1003834647979198,\n","  'test_rmse': 0.3168334969631838,\n","  'test_corr_coef': 0.9548895428536669,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('CatBoost', 'HyperbandPruner'): {'best_score': 0.10146578295486733,\n","  'best_params': {'iterations': 1000,\n","   'learning_rate': 0.05,\n","   'depth': 6,\n","   'l2_leaf_reg': 7,\n","   'border_count': 32,\n","   'min_data_in_leaf': 1,\n","   'rsm': 0.6,\n","   'bagging_temperature': 0,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10146578295486733,\n","  'test_rmse': 0.31853694127191484,\n","  'test_corr_coef': 0.9532680684984001,\n","  'pruner': 'HyperbandPruner'},\n"," ('CatBoost', 'ThresholdPruner'): {'best_score': 0.10239428808328108,\n","  'best_params': {'iterations': 500,\n","   'learning_rate': 0.1,\n","   'depth': 10,\n","   'l2_leaf_reg': 5,\n","   'border_count': 32,\n","   'min_data_in_leaf': 20,\n","   'rsm': 0.6,\n","   'bagging_temperature': 0,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10239428808328108,\n","  'test_rmse': 0.3199910750056649,\n","  'test_corr_coef': 0.9529055377273937,\n","  'pruner': 'ThresholdPruner'},\n"," ('CatBoost', 'WilcoxonPruner'): {'best_score': 0.10301394884876003,\n","  'best_params': {'iterations': 1000,\n","   'learning_rate': 0.03,\n","   'depth': 10,\n","   'l2_leaf_reg': 1,\n","   'border_count': 32,\n","   'min_data_in_leaf': 10,\n","   'rsm': 0.6,\n","   'bagging_temperature': 0,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10301394884876003,\n","  'test_rmse': 0.3209578614845881,\n","  'test_corr_coef': 0.9533780849549102,\n","  'pruner': 'WilcoxonPruner'},\n"," ('NGBoost', 'MedianPruner'): {'best_score': 0.10007444351282473,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.03,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.5,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10007444351282473,\n","  'test_rmse': 0.31634544964773037,\n","  'test_corr_coef': 0.9552595262902457,\n","  'pruner': 'MedianPruner'},\n"," ('NGBoost', 'NopPruner'): {'best_score': 0.10247400778264933,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.9,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10247400778264933,\n","  'test_rmse': 0.3201156162742601,\n","  'test_corr_coef': 0.9528579023018967,\n","  'pruner': 'NopPruner'},\n"," ('NGBoost', 'PatientPruner'): {'best_score': 0.10168533574344088,\n","  'best_params': {'n_estimators': 1000,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 1.0,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10168533574344088,\n","  'test_rmse': 0.3188813819329076,\n","  'test_corr_coef': 0.9542788438029136,\n","  'pruner': 'PatientPruner'},\n"," ('NGBoost', 'PercentilePruner'): {'best_score': 0.09677606097115385,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 1.0,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.09677606097115385,\n","  'test_rmse': 0.3110885098668124,\n","  'test_corr_coef': 0.9564376224985851,\n","  'pruner': 'PercentilePruner'},\n"," ('NGBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.09873552932280659,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.7,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.09873552932280659,\n","  'test_rmse': 0.3142221019005611,\n","  'test_corr_coef': 0.9562706177455038,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('NGBoost', 'HyperbandPruner'): {'best_score': 0.10703880786675476,\n","  'best_params': {'n_estimators': 1000,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 1.0,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10703880786675476,\n","  'test_rmse': 0.3271678588534558,\n","  'test_corr_coef': 0.9519326175897299,\n","  'pruner': 'HyperbandPruner'},\n"," ('NGBoost', 'ThresholdPruner'): {'best_score': 0.10393951274325544,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 1.0,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10393951274325544,\n","  'test_rmse': 0.3223965147814961,\n","  'test_corr_coef': 0.9536867428683047,\n","  'pruner': 'ThresholdPruner'},\n"," ('NGBoost', 'WilcoxonPruner'): {'best_score': 0.12368984124106991,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.03,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.5,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.12368984124106991,\n","  'test_rmse': 0.35169566565579097,\n","  'test_corr_coef': 0.943925995172727,\n","  'pruner': 'WilcoxonPruner'},\n"," ('HistGradientBoosting', 'MedianPruner'): {'best_score': 0.12929049519908128,\n","  'best_params': {'learning_rate': 0.1,\n","   'max_iter': 100,\n","   'max_depth': 5,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 15,\n","   'l2_regularization': 0.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.12929049519908128,\n","  'test_rmse': 0.3595698752663817,\n","  'test_corr_coef': 0.9398890335766664,\n","  'pruner': 'MedianPruner'},\n"," ('HistGradientBoosting', 'NopPruner'): {'best_score': 0.12758494403377102,\n","  'best_params': {'learning_rate': 0.05,\n","   'max_iter': 200,\n","   'max_depth': 5,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 63,\n","   'l2_regularization': 0.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.12758494403377102,\n","  'test_rmse': 0.3571903470612987,\n","  'test_corr_coef': 0.9412151289948386,\n","  'pruner': 'NopPruner'},\n"," ('HistGradientBoosting', 'PatientPruner'): {'best_score': 0.12592181052906196,\n","  'best_params': {'learning_rate': 0.1,\n","   'max_iter': 400,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 63,\n","   'l2_regularization': 0.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.12592181052906196,\n","  'test_rmse': 0.3548546329542028,\n","  'test_corr_coef': 0.9428457023277365,\n","  'pruner': 'PatientPruner'},\n"," ('HistGradientBoosting',\n","  'PercentilePruner'): {'best_score': 0.12758494403377102, 'best_params': {'learning_rate': 0.05,\n","   'max_iter': 500,\n","   'max_depth': 5,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': None,\n","   'l2_regularization': 0.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.12758494403377102, 'test_rmse': 0.3571903470612987, 'test_corr_coef': 0.9412151289948386, 'pruner': 'PercentilePruner'},\n"," ('HistGradientBoosting',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.11637483386311197, 'best_params': {'learning_rate': 0.1,\n","   'max_iter': 500,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 31,\n","   'l2_regularization': 1.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.11637483386311197, 'test_rmse': 0.34113755856415456, 'test_corr_coef': 0.9465434876799057, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('HistGradientBoosting',\n","  'HyperbandPruner'): {'best_score': 0.1155150567364688, 'best_params': {'learning_rate': 0.1,\n","   'max_iter': 400,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': None,\n","   'l2_regularization': 1.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.1155150567364688, 'test_rmse': 0.3398750604802724, 'test_corr_coef': 0.9469491597776423, 'pruner': 'HyperbandPruner'},\n"," ('HistGradientBoosting',\n","  'ThresholdPruner'): {'best_score': 0.1264288808167698, 'best_params': {'learning_rate': 0.1,\n","   'max_iter': 500,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': None,\n","   'l2_regularization': 1.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.1264288808167698, 'test_rmse': 0.35556839119467554, 'test_corr_coef': 0.9412981893132774, 'pruner': 'ThresholdPruner'},\n"," ('HistGradientBoosting',\n","  'WilcoxonPruner'): {'best_score': 0.12219411284571208, 'best_params': {'learning_rate': 0.15,\n","   'max_iter': 200,\n","   'max_depth': 5,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 31,\n","   'l2_regularization': 0.1,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.12219411284571208, 'test_rmse': 0.3495627452199563, 'test_corr_coef': 0.9432797492551531, 'pruner': 'WilcoxonPruner'},\n"," ('PGBM', 'MedianPruner'): {'best_score': 0.11498964846468326,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.15,\n","   'max_leaves': 32,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 5.0,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 0.5,\n","   'tree_correlation': 0.2,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.11498964846468326,\n","  'test_rmse': 0.3391012363066276,\n","  'test_corr_coef': 0.9479540611789176,\n","  'pruner': 'MedianPruner'},\n"," ('PGBM', 'NopPruner'): {'best_score': 0.09394586312570856,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.05,\n","   'max_leaves': 32,\n","   'min_split_gain': 0.0,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.1,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'normal'},\n","  'test_mse': 0.09394586312570856,\n","  'test_rmse': 0.30650589411250895,\n","  'test_corr_coef': 0.9576000690263383,\n","  'pruner': 'NopPruner'},\n"," ('PGBM', 'PatientPruner'): {'best_score': 0.0985452949992002,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'max_leaves': 19,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 1.0,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.0985452949992002,\n","  'test_rmse': 0.3139192491695917,\n","  'test_corr_coef': 0.9559437052993274,\n","  'pruner': 'PatientPruner'},\n"," ('PGBM', 'PercentilePruner'): {'best_score': 0.09401228832918966,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'max_leaves': 63,\n","   'min_split_gain': 0.0,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.0,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.09401228832918966,\n","  'test_rmse': 0.30661423373547037,\n","  'test_corr_coef': 0.9597301223560869,\n","  'pruner': 'PercentilePruner'},\n"," ('PGBM', 'SuccessiveHalvingPruner'): {'best_score': 0.09566403555916796,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.01,\n","   'max_leaves': 33,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 1.0,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'normal'},\n","  'test_mse': 0.09566403555916796,\n","  'test_rmse': 0.3092960322396134,\n","  'test_corr_coef': 0.9619154623103274,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('PGBM', 'HyperbandPruner'): {'best_score': 0.09745598873680562,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.1,\n","   'max_leaves': 46,\n","   'min_split_gain': 0.0,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.2,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'studentt'},\n","  'test_mse': 0.09745598873680562,\n","  'test_rmse': 0.3121794175419091,\n","  'test_corr_coef': 0.9598295301717349,\n","  'pruner': 'HyperbandPruner'},\n"," ('PGBM', 'ThresholdPruner'): {'best_score': 0.07967499065099139,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'max_leaves': 25,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'normal'},\n","  'test_mse': 0.07967499065099139,\n","  'test_rmse': 0.2822675869649071,\n","  'test_corr_coef': 0.9634227365395794,\n","  'pruner': 'ThresholdPruner'},\n"," ('PGBM', 'WilcoxonPruner'): {'best_score': 0.07891436383847483,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.05,\n","   'max_leaves': 25,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.2,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.07891436383847483,\n","  'test_rmse': 0.28091700524972646,\n","  'test_corr_coef': 0.9637400089687073,\n","  'pruner': 'WilcoxonPruner'},\n"," ('TabNet', 'MedianPruner'): {'best_score': 0.256252310039086,\n","  'best_params': {'n_d': 32,\n","   'n_a': 32,\n","   'n_steps': 3,\n","   'gamma': 1.3,\n","   'lambda_sparse': 0.001,\n","   'optimizer_params': {'lr': 0.02},\n","   'mask_type': 'entmax',\n","   'n_shared': 3,\n","   'n_independent': 2,\n","   'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n","   'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n","   'seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.256252310039086,\n","  'test_rmse': 0.5062136999717471,\n","  'test_corr_coef': 0.9156828968883542,\n","  'pruner': 'MedianPruner'},\n"," ('TabNet', 'NopPruner'): {'best_score': 0.19124593135250972,\n","  'best_params': {'n_d': 16,\n","   'n_a': 64,\n","   'n_steps': 5,\n","   'gamma': 1.0,\n","   'lambda_sparse': 0.001,\n","   'optimizer_params': {'lr': 0.02},\n","   'mask_type': 'entmax',\n","   'n_shared': 2,\n","   'n_independent': 3,\n","   'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n","   'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n","   'seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.19124593135250972,\n","  'test_rmse': 0.4373167403067366,\n","  'test_corr_coef': 0.921618700124402,\n","  'pruner': 'NopPruner'},\n"," ('TabNet', 'PatientPruner'): {'best_score': 0.10264087567577772,\n","  'best_params': {'n_d': 64,\n","   'n_a': 16,\n","   'n_steps': 3,\n","   'gamma': 1.5,\n","   'lambda_sparse': 0.0001,\n","   'optimizer_params': {'lr': 0.02},\n","   'mask_type': 'entmax',\n","   'n_shared': 1,\n","   'n_independent': 1,\n","   'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n","   'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n","   'seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10264087567577772,\n","  'test_rmse': 0.32037614717044355,\n","  'test_corr_coef': 0.9576665542688744,\n","  'pruner': 'PatientPruner'},\n"," ('TabNet', 'PercentilePruner'): {'best_score': 0.13901091143338964,\n","  'best_params': {'n_d': 16,\n","   'n_a': 16,\n","   'n_steps': 3,\n","   'gamma': 1.3,\n","   'lambda_sparse': 0.001,\n","   'optimizer_params': {'lr': 0.02},\n","   'mask_type': 'sparsemax',\n","   'n_shared': 1,\n","   'n_independent': 1,\n","   'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n","   'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n","   'seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.13901091143338964,\n","  'test_rmse': 0.37284167073087426,\n","  'test_corr_coef': 0.9399527518507529,\n","  'pruner': 'PercentilePruner'},\n"," ('TabNet', 'SuccessiveHalvingPruner'): {'best_score': 0.261234520655512,\n","  'best_params': {'n_d': 32,\n","   'n_a': 16,\n","   'n_steps': 3,\n","   'gamma': 2.0,\n","   'lambda_sparse': 0.001,\n","   'optimizer_params': {'lr': 0.02},\n","   'mask_type': 'entmax',\n","   'n_shared': 3,\n","   'n_independent': 1,\n","   'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n","   'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n","   'seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.261234520655512,\n","  'test_rmse': 0.5111110648924674,\n","  'test_corr_coef': 0.9008124074450636,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('TabNet', 'HyperbandPruner'): {'best_score': 0.6397804309619128,\n","  'best_params': {'n_d': 16,\n","   'n_a': 8,\n","   'n_steps': 3,\n","   'gamma': 1.3,\n","   'lambda_sparse': 0.0001,\n","   'optimizer_params': {'lr': 0.02},\n","   'mask_type': 'sparsemax',\n","   'n_shared': 3,\n","   'n_independent': 2,\n","   'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n","   'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n","   'seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.6397804309619128,\n","  'test_rmse': 0.7998627575790191,\n","  'test_corr_coef': 0.8624020900755582,\n","  'pruner': 'HyperbandPruner'},\n"," ('TabNet', 'ThresholdPruner'): {'best_score': 0.3406831379378952,\n","  'best_params': {'n_d': 8,\n","   'n_a': 32,\n","   'n_steps': 7,\n","   'gamma': 1.5,\n","   'lambda_sparse': 0.01,\n","   'optimizer_params': {'lr': 0.02},\n","   'mask_type': 'entmax',\n","   'n_shared': 1,\n","   'n_independent': 1,\n","   'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n","   'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n","   'seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.3406831379378952,\n","  'test_rmse': 0.58368068148423,\n","  'test_corr_coef': 0.8686525226904566,\n","  'pruner': 'ThresholdPruner'},\n"," ('TabNet', 'WilcoxonPruner'): {'best_score': 0.22752917667402095,\n","  'best_params': {'n_d': 16,\n","   'n_a': 32,\n","   'n_steps': 5,\n","   'gamma': 1.0,\n","   'lambda_sparse': 0.0001,\n","   'optimizer_params': {'lr': 0.02},\n","   'mask_type': 'entmax',\n","   'n_shared': 3,\n","   'n_independent': 3,\n","   'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n","   'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n","   'seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.22752917667402095,\n","  'test_rmse': 0.47700018519285814,\n","  'test_corr_coef': 0.9307376015029869,\n","  'pruner': 'WilcoxonPruner'}}"]},{"cell_type":"markdown","source":["# **Conformal Predictions with XGBoost**"],"metadata":{"id":"fJazciE3ikar"}},{"cell_type":"code","source":["# Get the best hyperparameters for XGBRegressor\n","best_params = get_best_model_params(best_scores_autosampler, 'XGBoost')\n","\n","# Define the quantiles you want to predict\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","# Dictionary to store models for each quantile\n","models_quantile = {}\n","\n","# DataFrame to store predictions\n","predictions_XGB_df = pd.DataFrame()\n","\n","# Train a model for each quantile and make predictions\n","for q in quantiles:\n","    # Create a copy of best_params to avoid modifying the original\n","    params = best_params.copy()\n","\n","    # Adjust according to your XGBoost version\n","    params.update({\n","        'objective': 'reg:quantileerror',  # Use the correct objective\n","        'quantile_alpha': q,                         # Use 'alpha' to set the quantile level\n","        'random_state': 42\n","    })\n","\n","    # Initialize the model with the updated parameters\n","    model = XGBRegressor(**params)\n","\n","    # Fit the model\n","    model.fit(X_train, y_train)\n","\n","    # Store the model\n","    models_quantile[q] = model\n","\n","    # Make predictions\n","    predictions = model.predict(X_test)\n","\n","    # Add predictions to the DataFrame\n","    predictions_XGB_df[q] = predictions\n","\n","# Add actual target values to the DataFrame\n","predictions_XGB_df['Actual'] = y_test.values.ravel()\n","\n","# Print the DataFrame with predictions for each quantile\n","print(predictions_XGB_df.head())"],"metadata":{"id":"2BPk8z_WH34-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quantile_regression_print(predictions_XGB_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/XGBoost.xlsx\")"],"metadata":{"id":"2-1CG1pkIA6a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluation_features_print(predictions_XGB_df,x_test,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/XGBoost.xlsx\")"],"metadata":{"id":"AL678AvIIHSu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate_uncertainity_matrix(predictions_XGB_df, quantiles, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/XGBoost.xlsx\", model_name='XGBoost')"],"metadata":{"id":"653hv-mNIEaN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calibrate_and_plot_intervals(predictions_XGB_df, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/XGBoost.xlsx\")"],"metadata":{"id":"_DPkjnbFIcX6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_quantile_intervals_to_excel(predictions_XGB_df, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/XGBoost.xlsx\")"],"metadata":{"id":"sKSLvLdOIfcp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conformal Predictions with Lightgbm**"],"metadata":{"id":"Y6hr1MPKiExQ"}},{"cell_type":"code","source":["best_params = get_best_model_params(best_scores_autosampler, 'LightGBM')\n","\n","# Define the quantiles you want to predict\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","# Dictionary to store models for each quantile\n","models_quantile = {}\n","\n","# DataFrame to store predictions\n","predictions_LGBM_df = pd.DataFrame()\n","\n","\n","# Train a model for each quantile and make predictions using LightGBM\n","for q in quantiles:\n","    # Create a copy of best_params to avoid modifying the original\n","    params = best_params.copy()\n","\n","    # Update params with quantile-specific settings\n","    params.update({\n","        'objective': 'quantile',\n","        'alpha': q,\n","        'random_state': 42\n","    })\n","\n","    # Initialize the model with the updated parameters\n","    model = LGBMRegressor(**params)\n","\n","    # Fit the model\n","    model.fit(X_train, y_train)\n","\n","    # Store the model\n","    models_quantile[q] = model\n","\n","    # Make predictions\n","    predictions = model.predict(X_test)\n","\n","    # Add predictions to the DataFrame\n","    predictions_LGBM_df[q] = predictions\n","\n","# Add actual target values to the DataFrame\n","predictions_LGBM_df['Actual'] = y_test.values.ravel()\n","\n","# Print the DataFrame with predictions for each quantile\n","print(predictions_LGBM_df.head())"],"metadata":{"id":"de5n4NTsqpWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quantile_regression_print(predictions_LGBM_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/LightGBM.xlsx\")"],"metadata":{"id":"RG2aaIUwqrtb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluation_features_print(predictions_LGBM_df,x_test,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/LightGBM.xlsx\")"],"metadata":{"id":"1u21SGnZ-MwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate_uncertainity_matrix(predictions_LGBM_df, quantiles, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/LightGBM.xlsx\", model_name='LightGBM')"],"metadata":{"id":"BjCH_JG2qqdt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calibrate_and_plot_intervals(predictions_LGBM_df, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/LightGBM.xlsx\")"],"metadata":{"id":"NgcLirets5-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_quantile_intervals_to_excel(predictions_LGBM_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/LightGBM.xlsx\")"],"metadata":{"id":"_XjJ_jFntYgA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conformal Predictions with GPBoost**"],"metadata":{"id":"qKPXAUFMi6nf"}},{"cell_type":"code","source":["# Get the best hyperparameters for GPBoostRegressor\n","best_params = get_best_model_params(best_scores_autosampler, 'GPBoost')\n","\n","# Define the quantiles you want to predict\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","# Dictionary to store models for each quantile\n","models_quantile = {}\n","\n","# DataFrame to store predictions\n","predictions_GPBoost_df = pd.DataFrame()\n","\n","# Parameters that may conflict with quantile-specific settings\n","incompatible_keys = ['objective', 'alpha', 'quantile_alpha', 'boosting_type', 'metric', 'eval_metric']\n","\n","# Train a model for each quantile and make predictions\n","for q in quantiles:\n","    # Create a copy of best_params to avoid modifying the original\n","    params = best_params.copy()\n","\n","    # Remove incompatible parameters\n","    for key in incompatible_keys:\n","        params.pop(key, None)\n","\n","    # Update params with quantile-specific settings\n","    params.update({\n","        'objective': 'quantile',\n","        'alpha': q,\n","        'random_state': 42\n","    })\n","\n","    # Initialize the model with the updated parameters\n","    model = GPBoostRegressor(**params)\n","\n","    # Fit the model\n","    model.fit(X_train, y_train)\n","\n","    # Store the model\n","    models_quantile[q] = model\n","\n","    # Make predictions\n","    predictions = model.predict(X_test)\n","\n","    # Add predictions to the DataFrame\n","    predictions_GPBoost_df[q] = predictions\n","\n","# Add actual target values to the DataFrame\n","predictions_GPBoost_df['Actual'] = y_test.values.ravel()\n","\n","# Print the DataFrame with predictions for each quantile\n","print(predictions_GPBoost_df.head())"],"metadata":{"id":"hf3FsCDTJmRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quantile_regression_print(predictions_GPBoost_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/GPBoost.xlsx\")"],"metadata":{"id":"jhw_Uo97Jt48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluation_features_print(predictions_GPBoost_df,x_test,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/GPBoost.xlsx\")"],"metadata":{"id":"tI5bcjfKJto2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate_uncertainity_matrix(predictions_GPBoost_df, quantiles,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/GPBoost.xlsx\", model_name='GPBoost')"],"metadata":{"id":"kFXj2a2kJtiL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calibrate_and_plot_intervals(predictions_GPBoost_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/GPBoost.xlsx\")"],"metadata":{"id":"qZaK-mi5JtaM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_quantile_intervals_to_excel(predictions_GPBoost_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/GPBoost.xlsx\")"],"metadata":{"id":"3RSM3SmGJtUt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conformal Predictions with NGBoost**"],"metadata":{"id":"iLzCJFvijZwX"}},{"cell_type":"code","source":["# Correct best_params assignment\n","best_params = get_best_model_params(best_scores_autosampler, 'NGBoost')\n","\n","# DataFrame to store predictions\n","predictions_NGB_df = pd.DataFrame()\n","\n","# Remove 'Score' and 'Dist' if present in best_params\n","for key in ['Score', 'Dist']:\n","    best_params.pop(key, None)\n","\n","# Update params with model settings\n","best_params.update({\n","    'Dist': Normal,\n","    'Score': LogScore,\n","    'random_state': 42,\n","    'verbose': True\n","})\n","\n","# Initialize and fit the NGBoost model once\n","model = NGBRegressor(**best_params)\n","\n","# Fit the model\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","pred_dist = model.pred_dist(X_test)\n","\n","# Extract the mean (mu) and standard deviation (sigma) of the predicted distributions\n","mu = pred_dist.loc    # Mean predictions\n","sigma = pred_dist.scale  # Standard deviation predictions\n","\n","# Define the quantiles you want to predict\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","# For each quantile, compute predictions\n","for q in quantiles:\n","    # Calculate the z-score for the desired quantile\n","    z = norm.ppf(q)\n","\n","    # Compute the quantile prediction per sample\n","    predictions = mu + z * sigma\n","\n","    # Add predictions to the DataFrame\n","    predictions_NGB_df[q] = predictions\n","\n","# Add actual target values to the DataFrame\n","predictions_NGB_df['Actual'] = y_test.values.ravel()\n","\n","# Print the DataFrame with predictions for each quantile\n","print(predictions_NGB_df.head())"],"metadata":{"id":"h5DVhJkALJnz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quantile_regression_print(predictions_NGB_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/NGBoost.xlsx\")"],"metadata":{"id":"fJ2CPDRWLM-6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluation_features_print(predictions_NGB_df,x_test,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/NGBoost.xlsx\")"],"metadata":{"id":"gTWQrwwfLQyh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate_uncertainity_matrix(predictions_NGB_df, quantiles,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/NGBoost.xlsx\", model_name='NGBoost')"],"metadata":{"id":"-l88-eYuLSYb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calibrate_and_plot_intervals(predictions_NGB_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/NGBoost.xlsx\")"],"metadata":{"id":"VefD616eLT5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_quantile_intervals_to_excel(predictions_NGB_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/NGBoost.xlsx\")"],"metadata":{"id":"NRH_r_Q7LWBz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conformal Predictions with Gradient Boosting**"],"metadata":{"id":"H3xn7LD6jquL"}},{"cell_type":"code","source":["best_params = get_best_model_params(best_scores_autosampler, 'GBM')\n","\n","\n","# Define the quantiles you want to predict\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","# Dictionary to store models for each quantile\n","models_quantile = {}\n","\n","# DataFrame to store predictions\n","predictions_GBR_df = pd.DataFrame()\n","\n","# Custom quantile loss function\n","def quantile_loss(q, y_true, y_pred):\n","    e = y_true - y_pred\n","    return np.mean(np.maximum(q * e, (q - 1) * e))\n","\n","# Train a model for each quantile and make predictions using GradientBoostingRegressor\n","for q in quantiles:\n","\n","    params = best_params.copy()\n","\n","    params.update({\n","        'loss': 'quantile',\n","        'alpha': q,\n","        'random_state': 42\n","    })\n","    # Initialize the model with quantile-specific settings\n","    model = GradientBoostingRegressor(**params)\n","\n","    # Fit the model\n","    model.fit(X_train, y_train)\n","\n","    # Store the model\n","    models_quantile[q] = model\n","\n","    # Make predictions\n","    predictions = model.predict(X_test)\n","\n","    # Add predictions to the DataFrame\n","    predictions_GBR_df[q] = predictions\n","\n","# Add actual target values to the DataFrame\n","predictions_GBR_df['Actual'] = y_test.values.ravel()\n","\n","# Print the DataFrame with predictions for each quantile\n","print(predictions_GBR_df.head())"],"metadata":{"id":"LlfLCosvNjNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quantile_regression_print(predictions_GBR_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/Gradient Boosting.xlsx\")"],"metadata":{"id":"eKXlPec0QL0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluation_features_print(predictions_GBR_df,x_test,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/Gradient Boosting.xlsx\")"],"metadata":{"id":"Yu7jhNIjQQqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate_uncertainity_matrix(predictions_GBR_df, quantiles,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/Gradient Boosting.xlsx\", model_name='GBM')"],"metadata":{"id":"KdKxFuXiQRX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calibrate_and_plot_intervals(predictions_GBR_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/Gradient Boosting.xlsx\")"],"metadata":{"id":"GUFAwKtdQTRE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_quantile_intervals_to_excel(predictions_GBR_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/Gradient Boosting.xlsx\")"],"metadata":{"id":"7t8NUEG7Rocw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conformal Predictions with CatBoost**"],"metadata":{"id":"Jbu18SHsjslS"}},{"cell_type":"code","source":["# Get the best hyperparameters for CatBoostRegressor\n","best_params = get_best_model_params(best_scores_autosampler, 'CatBoost')\n","\n","# Define the quantiles you want to predict\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","# Dictionary to store models for each quantile\n","models_quantile = {}\n","\n","# DataFrame to store predictions\n","predictions_CatBoost_df = pd.DataFrame()\n","\n","# Parameters that may conflict with quantile-specific settings\n","incompatible_keys = ['objective', 'loss_function', 'eval_metric']\n","\n","# Train a model for each quantile and make predictions\n","for q in quantiles:\n","    # Create a copy of best_params to avoid modifying the original\n","    params = best_params.copy()\n","\n","    # Remove incompatible parameters\n","    for key in incompatible_keys:\n","        params.pop(key, None)\n","\n","    # Update params with quantile-specific settings\n","    params.update({\n","        'loss_function': 'Quantile:alpha={}'.format(q),\n","        'random_seed': 42\n","    })\n","\n","    # Initialize the model with the updated parameters\n","    model = CatBoostRegressor(**params)\n","\n","    # Fit the model\n","    model.fit(X_train, y_train, verbose=0)\n","\n","    # Store the model\n","    models_quantile[q] = model\n","\n","    # Make predictions\n","    predictions = model.predict(X_test)\n","\n","    # Add predictions to the DataFrame\n","    predictions_CatBoost_df[q] = predictions\n","\n","# Add actual target values to the DataFrame\n","predictions_CatBoost_df['Actual'] = y_test.values.ravel()\n","\n","# Print the DataFrame with predictions for each quantile\n","print(predictions_CatBoost_df.head())"],"metadata":{"id":"nN9s_8FoiaAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quantile_regression_print(predictions_CatBoost_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/CatBoost.xlsx\")"],"metadata":{"id":"57sTwIXni-Bs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluation_features_print(predictions_CatBoost_df,x_test,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/CatBoost.xlsx\")"],"metadata":{"id":"xrOG4aHzjBqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate_uncertainity_matrix(predictions_CatBoost_df, quantiles,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/CatBoost.xlsx\", model_name='CatBoost')"],"metadata":{"id":"-dZ8pmJdjCNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calibrate_and_plot_intervals(predictions_CatBoost_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/CatBoost.xlsx\")"],"metadata":{"id":"IVhK5qj0jFDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_quantile_intervals_to_excel(predictions_CatBoost_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/CatBoost.xlsx\")"],"metadata":{"id":"e_J5x-72jJjD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-uCHZ-10ZKR"},"source":["# **Conformal Predictions with HistGradientBoosting**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSGM7tTe0ZKR"},"outputs":[],"source":["\n","# Assume best_params is a dictionary containing the best parameters for HistGradientBoostingRegressor\n","best_params = get_best_model_params(best_scores_autosampler, 'HGBR')\n","\n","# Define the quantiles you want to predict\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","# Dictionary to store models for each quantile\n","models_quantile = {}\n","\n","# DataFrame to store predictions\n","predictions_HGBR_df = pd.DataFrame()\n","\n","# Train a model for each quantile and make predictions using HistGradientBoostingRegressor\n","for q in quantiles:\n","    # Create a copy of best_params to avoid modifying the original\n","    params = best_params.copy()\n","\n","    # Update params with quantile-specific settings\n","    params.update({\n","        'loss': 'quantile',\n","        'quantile': q,\n","        'random_state': 42\n","    })\n","\n","    # Initialize the model with the updated parameters\n","    model = HistGradientBoostingRegressor(**params)\n","\n","    # Fit the model\n","    model.fit(X_train, y_train)\n","\n","    # Store the model\n","    models_quantile[q] = model\n","\n","    # Make predictions\n","    predictions = model.predict(X_test)\n","\n","    # Add predictions to the DataFrame\n","    predictions_HGBR_df[q] = predictions\n","\n","# Add actual target values to the DataFrame\n","predictions_HGBR_df['Actual'] = y_test.values.ravel()\n","\n","# Print the DataFrame with predictions for each quantile\n","print(predictions_HGBR_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NMchW8L0ZKR"},"outputs":[],"source":["quantile_regression_print(predictions_HGBR_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/HGBM.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tr4o0TGq0ZKR"},"outputs":[],"source":["evaluation_features_print(predictions_HGBR_df,x_test,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/HGBM.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zCVGmztl0ZKR"},"outputs":[],"source":["evaluate_uncertainity_matrix(predictions_HGBR_df, quantiles,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/HGBM.xlsx\", model_name='HGBM')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCNmETbrnt3a"},"outputs":[],"source":["calibrate_and_plot_intervals(predictions_HGBR_df, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/HGBM.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISkUSmBRntux"},"outputs":[],"source":["plot_quantile_intervals_to_excel(predictions_HGBR_df, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/HGBM.xlsx\")"]},{"cell_type":"markdown","metadata":{"id":"-i5Nx__sgW4J"},"source":["# **Conformal Predictions with PGBM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnOv0BOscsOY"},"outputs":[],"source":["class PGBMWrapper(BaseEstimator, RegressorMixin):\n","    def __init__(self, **params):\n","        self.params = params\n","        self.model = None\n","\n","    def fit(self, X, y):\n","        X_ = X.to_numpy() if hasattr(X, \"to_numpy\") else np.array(X)\n","        y_ = y.to_numpy() if hasattr(y, \"to_numpy\") else np.array(y)\n","        self.model = PGBM()\n","        self.model.train(\n","            train_set=(X_, y_),\n","            objective=mseloss_objective,\n","            metric=rmseloss_metric,\n","            params=self.params\n","        )\n","        return self\n","\n","    def predict(self, X):\n","        X_ = X.to_numpy() if hasattr(X, \"to_numpy\") else np.array(X)\n","        return self.model.predict(X_).numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPfQZ0INgdd5"},"outputs":[],"source":["# Assuming best_params is obtained correctly\n","best_params = get_best_model_params(best_scores_autosampler, 'PGBM')\n","\n","# Remove any conflicting parameters from best_params\n","incompatible_keys = ['Dist', 'Score']\n","for key in incompatible_keys:\n","    best_params.pop(key, None)\n","\n","# Initialize PGBM model\n","pgbm_model = PGBM()\n","def mseloss_objective(yhat, y, sample_weight=None):\n","    # Ensure that yhat and y are PyTorch tensors\n","    if not torch.is_tensor(yhat):\n","        yhat = torch.from_numpy(np.array(yhat)).float()\n","    if not torch.is_tensor(y):\n","        y = torch.from_numpy(np.array(y)).float()\n","    gradient = yhat - y\n","    hessian = torch.ones_like(yhat)\n","    return gradient, hessian\n","\n","def rmseloss_metric(yhat, y, sample_weight=None):\n","    # Ensure that yhat and y are PyTorch tensors\n","    if not torch.is_tensor(yhat):\n","        yhat = torch.from_numpy(np.array(yhat)).float()\n","    if not torch.is_tensor(y):\n","        y = torch.from_numpy(np.array(y)).float()\n","    loss = torch.sqrt(torch.mean((yhat - y) ** 2))\n","    return loss\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","X_test = np.array(X_test)\n","y_test = np.array(y_test)\n","\n","# Fit the model\n","pgbm_model.train((X_train, y_train), objective=mseloss_objective, metric=rmseloss_metric, params=best_params)\n","\n","# Predict the distribution\n","pred_dist = pgbm_model.predict_dist(X_test)\n","\n","# Define the quantiles you want to predict\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","# DataFrame to store predictions\n","predictions_PGBM_df = pd.DataFrame()\n","\n","# Calculate and store quantiles\n","for q in quantiles:\n","    predictions_PGBM_df[q] = np.quantile(pred_dist, q, axis=0)\n","\n","# Add actual target values to the DataFrame\n","predictions_PGBM_df['Actual'] = y_test.ravel()\n","\n","# Print the DataFrame with predictions for each quantile\n","print(predictions_PGBM_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17cBxar3r1I9"},"outputs":[],"source":["quantile_regression_print(predictions_PGBM_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/PGBM.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3Dc1IFtseAD"},"outputs":[],"source":["evaluation_features_print(predictions_PGBM_df,x_test,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/PGBM.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UYKTs0vgse4r"},"outputs":[],"source":["evaluate_uncertainity_matrix(predictions_PGBM_df, quantiles, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/PGBM.xlsx\", model_name='PGBM')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WY49mHXsd0u"},"outputs":[],"source":["calibrate_and_plot_intervals(predictions_PGBM_df, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/PGBM.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X0NwXwAhsdxn"},"outputs":[],"source":["plot_quantile_intervals_to_excel(predictions_PGBM_df,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/PGBM.xlsx\")"]},{"cell_type":"markdown","source":["# **Conformal Prediction with TabNet**"],"metadata":{"id":"nSGdX7fuKG6H"}},{"cell_type":"code","source":["class TabNetRegressorUniversal(TabNetRegressor):\n","    def fit(self, X, y, *args, **kwargs):\n","        y_ = np.array(y)\n","        if y_.ndim == 1:\n","            y_ = y_.reshape(-1, 1)\n","        return super().fit(X, y_, *args, **kwargs)\n","    def predict(self, X, *args, **kwargs):\n","        preds = super().predict(X, *args, **kwargs)\n","        return np.array(preds).flatten()"],"metadata":{"id":"Xfig1HqWKOKK","executionInfo":{"status":"ok","timestamp":1755074482139,"user_tz":-330,"elapsed":2,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Best parameters for TabNet\n","best_params = get_best_model_params(best_scores_autosampler, 'TabNet')\n","def quantile_loss(y_pred, y_true, quantile):\n","    \"\"\"\n","    Calculates the quantile loss.\n","    y_true: actual values\n","    y_pred: predicted values\n","    quantile: the quantile level (e.g., 0.5 for median)\n","    \"\"\"\n","    error = y_true - y_pred\n","    # The core formula for quantile loss\n","    loss = torch.mean(torch.max(quantile * error, (quantile - 1) * error))\n","    return loss\n","\n","# --- Your data preparation remains the same ---\n","quantiles = [0.05, 0.1, 0.15, 0.2, 0.3,\n","             0.4, 0.5, 0.6, 0.7, 0.8,\n","             0.85, 0.9, 0.95]\n","\n","y_train = y_train.to_numpy().reshape(-1, 1)\n","y_test = y_test.to_numpy().reshape(-1, 1)\n","\n","models_tabnet_quantile = {}\n","predictions_TabNet_df = pd.DataFrame()\n","predictions_TabNet_df['Actual'] = y_test.ravel()\n","\n","# --- The main loop with the fix ---\n","for q in quantiles:\n","    params = best_params.copy()\n","\n","    model = TabNetRegressorUniversal(**params)\n","\n","    # STEP 2: Create a callable lambda function for the current quantile\n","    current_loss_fn = lambda y_pred, y_true: quantile_loss(y_pred, y_true, q)\n","\n","    # STEP 3: Pass the callable function to loss_fn\n","    model.fit(X_train, y_train,\n","              loss_fn=current_loss_fn,  # Pass the function, not a string\n","              # The `quantile` param is no longer needed here\n","              max_epochs=100,\n","              patience=5,\n","              batch_size=1024,\n","              eval_set=[(X_test, y_test)])\n","\n","    models_tabnet_quantile[q] = model\n","    preds = model.predict(X_test)\n","    predictions_TabNet_df[q] = preds.ravel()\n","\n","# Print first few rows to check\n","print(predictions_TabNet_df.head())"],"metadata":{"id":"8vNlVIEaKQwH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755074776304,"user_tz":-330,"elapsed":6304,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}},"outputId":"0b083118-2ee6-4040-9161-f31f9599226a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_0_mse = 1.06403\n","\n","Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_0_mse = 1.36384\n","\n","Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_0_mse = 1.3498\n","\n","Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_0_mse = 1.85534\n","\n","Early stopping occurred at epoch 7 with best_epoch = 2 and best_val_0_mse = 3.13313\n","\n","Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_0_mse = 1.29631\n","\n","Early stopping occurred at epoch 6 with best_epoch = 1 and best_val_0_mse = 2.17667\n","\n","Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_0_mse = 0.31777\n","\n","Early stopping occurred at epoch 36 with best_epoch = 31 and best_val_0_mse = 0.25557\n","\n","Early stopping occurred at epoch 12 with best_epoch = 7 and best_val_0_mse = 1.08888\n","\n","Early stopping occurred at epoch 5 with best_epoch = 0 and best_val_0_mse = 6.54434\n","\n","Early stopping occurred at epoch 5 with best_epoch = 0 and best_val_0_mse = 9.65298\n","\n","Early stopping occurred at epoch 5 with best_epoch = 0 and best_val_0_mse = 10.15594\n","   Actual      0.05       0.1      0.15       0.2       0.3       0.4  \\\n","0     0.4 -1.174437  0.280527 -0.696403 -3.502129 -1.570063 -3.259190   \n","1     0.2  0.431946  0.801557  1.744675 -0.241798  2.617910  0.299284   \n","2     1.1  0.298351  0.436303  0.479610  0.737281  1.612009  1.146467   \n","3     1.6 -2.323003 -1.745331 -1.667556 -2.474454 -1.151502 -0.494221   \n","4     0.2 -0.158480  0.205208 -0.084283  0.328988  0.970592  0.985200   \n","\n","        0.5       0.6       0.7       0.8      0.85       0.9      0.95  \n","0 -1.429335  0.032154  0.337057  1.629743 -0.561364 -0.430972 -0.297916  \n","1  2.914176  0.967021  0.399282  3.134986  4.692671  4.818992  5.140655  \n","2  2.424778  0.478764  1.004333  0.699282  1.863043  1.725912  1.593049  \n","3  0.040960  0.816922  1.018151  3.086065  0.665475  0.894981  1.044477  \n","4  1.504284  1.101082  0.585318  1.395504  2.024545  2.078177  2.167513  \n"]}]},{"cell_type":"code","source":["quantile_regression_print(\n","    predictions_TabNet_df,\n","    \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/TabNet.xlsx\"\n",")"],"metadata":{"id":"E4jHS-wHKQ-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755075547777,"user_tz":-330,"elapsed":4884,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}},"outputId":"694f0fd4-246a-4a84-984f-adf171203d24"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["First few actual values: [0.4 0.2 1.1 1.6 0.2]\n","Coverage of 90% prediction interval: 69.23%\n"]}]},{"cell_type":"code","source":["evaluation_features_print(\n","    predictions_TabNet_df,\n","    X_test,\n","    \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/TabNet.xlsx\"\n",")\n"],"metadata":{"id":"571kvR6JKRW4","executionInfo":{"status":"ok","timestamp":1755075579577,"user_tz":-330,"elapsed":4408,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["evaluate_uncertainity_matrix(\n","    predictions_TabNet_df,\n","    quantiles,\n","    \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/TabNet.xlsx\",\n","    model_name='TabNet'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBClns1eqAMR","executionInfo":{"status":"ok","timestamp":1755075605177,"user_tz":-330,"elapsed":1442,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}},"outputId":"9c2541d0-c0d4-4f34-a7e8-9d9debe35428"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'empirical_quantiles': [0.16666666666666666,\n","  0.3974358974358974,\n","  0.1794871794871795,\n","  0.28205128205128205,\n","  0.5128205128205128,\n","  0.3974358974358974,\n","  0.6923076923076923,\n","  0.6923076923076923,\n","  0.5897435897435898,\n","  0.7692307692307693,\n","  0.7307692307692307,\n","  0.782051282051282,\n","  0.8205128205128205],\n"," 'average_interval_lengths': [1.1512811, 1.1112128, 1.6111175],\n"," 'coverage_levels': [0.6, 0.8, 0.9],\n"," 'average_nll': 519603788096.1773,\n"," 'average_crps': 0.41507377979903626,\n"," 'nll_values': array([ 2.31656327e+01,  3.07541810e+00,  5.65186200e+00,  2.10212088e+00,\n","         2.27370800e+00,  2.73650395e+10,  5.61869202e-03,  2.42230967e+00,\n","         2.60882327e+00,  2.62375408e+00,  3.45741495e+00,  8.41168483e-01,\n","         8.76161204e+12,  4.28000226e+00,  2.78011501e-01,  5.98221248e-01,\n","         1.57251819e+00,  5.13419099e-01,  1.47057867e+00,  1.45295894e+02,\n","         6.16592555e+12,  3.16019208e-01, -6.51047564e-02,  2.63231737e-01,\n","         2.96965493e+00,  1.72575830e+00,  2.64605474e+00,  9.65477757e-01,\n","         1.36424856e+00,  9.63491613e+12,  1.28020991e+00,  1.82518214e+00,\n","        -8.98671607e-01,  1.97666228e+00, -2.53740176e-01,  4.37258766e+00,\n","         1.69432855e-01,  1.12577992e+00,  1.59913267e+00,  2.02650231e+00,\n","         2.86558732e+00,  6.38256739e-01, -1.37613062e+00,  1.24327984e+00,\n","         7.21392456e-01,  4.06338962e+01,  1.58480489e+00,  2.36012812e-01,\n","         5.71777988e+12,  8.40819950e-01,  1.19801051e+00,  2.20189270e+00,\n","         7.90423515e+00,  2.03241047e+00,  9.50101116e-01, -1.03840094e-01,\n","         3.75056758e+00,  1.87453913e+00,  2.48023209e-01,  5.97535590e+00,\n","         1.89756270e+00,  6.38822678e-01,  3.55300130e-01,  1.42555290e+02,\n","        -1.24195695e-01, -5.24970005e-01,  1.95546526e+00,  8.00094607e+12,\n","         8.23575617e-01,  1.67879452e+00, -6.26147532e-02,  2.22055077e+12,\n","         9.78299790e-01,  8.75153402e-01,  1.39713362e+00,  1.63879028e+00,\n","         1.94562794e+00,  7.72592375e-01]),\n"," 'crps_values': array([0.66726643, 0.98201348, 0.20330059, 1.12850871, 0.46517486,\n","        0.51870198, 0.13184769, 0.5847259 , 0.5472753 , 1.70221635,\n","        0.5343011 , 0.34759962, 0.72557806, 0.30241981, 0.498867  ,\n","        0.10329891, 0.21116321, 0.1484984 , 0.18269843, 0.09719202,\n","        0.30786331, 0.60315302, 0.08448599, 0.24247695, 0.74018951,\n","        0.39062259, 0.79981982, 0.42935787, 0.25284708, 0.70671968,\n","        0.15712424, 0.48122281, 0.16399804, 0.29293069, 0.15793605,\n","        0.23830445, 0.1554162 , 0.44410926, 0.19115634, 0.51963507,\n","        0.30623639, 0.05375307, 0.07926157, 0.39958158, 0.38784468,\n","        0.80823492, 0.46308742, 0.11400988, 0.50873115, 0.31248807,\n","        0.37780187, 0.67222327, 0.27391565, 0.5415053 , 0.23208294,\n","        0.2087911 , 0.65388235, 0.31078427, 0.14118422, 0.5223033 ,\n","        0.5045256 , 0.39710723, 0.1619954 , 0.26837615, 0.22728263,\n","        0.12743089, 0.41242818, 0.7616234 , 0.20299822, 0.36416291,\n","        0.15248141, 1.46304687, 0.53183517, 0.49218765, 0.38570339,\n","        0.26914886, 0.38881472, 0.45488627])}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["calibrate_and_plot_intervals(\n","    predictions_TabNet_df,\n","    \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/TabNet.xlsx\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apmBnAq4qDpq","executionInfo":{"status":"ok","timestamp":1755075605915,"user_tz":-330,"elapsed":721,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}},"outputId":"b45df52b-f12b-4d34-c553-fe0f282e384c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["The empirical coverage before calibration is: 74.36%\n","The empirical coverage after calibration is: 89.74%\n"]}]},{"cell_type":"code","source":["plot_quantile_intervals_to_excel(\n","    predictions_TabNet_df,\n","    \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/Quantile_Regression/TabNet.xlsx\"\n",")"],"metadata":{"id":"mQUy2cVRqIKq","executionInfo":{"status":"ok","timestamp":1755075619433,"user_tz":-330,"elapsed":829,"user":{"displayName":"DANESH SELWAL","userId":"10685518505246578435"}}},"execution_count":28,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["N5BWBoV8sPyB","QVvIIfafc2bL","54GBQEKIMTH1","Y6hr1MPKiExQ","qKPXAUFMi6nf","iLzCJFvijZwX","H3xn7LD6jquL","Jbu18SHsjslS","z-uCHZ-10ZKR","-i5Nx__sgW4J"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}